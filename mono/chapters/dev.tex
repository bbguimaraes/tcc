\chapter{Desenvolvimento do experimento}

Nesse capítulo é apresentado o desenvolvimento do experimento, baseado nos conceitos apresentados nos capítulos anteriores. Em especial, esse capítulo mostra como as ferramentas do capítulo \ref{chap:prop} (\nameref{chap:prop}) foram utilizadas para a comparação dos resultados dos algoritmos apresentados no capítulo \ref{chap:ais} (\nameref{chap:ais}).

\section{Preparação dos dados}

Os dois conjuntos de dados utilizados (\emph{cr.ger} e \emph{cr.aust}) se encontravam em formato de texto, com os atributos separados por espaços e as instâncias separadas pelo caractere nova linha. As listagens \ref{lst:dev_data_ger} e \ref{lst:dev_data_aust} mostram as instâncias dos conjuntos de dados no formato do arquivo original (a primeira coluna representa o número da linha, e não faz parte dos dados)\footnote{Aqui são mostradas apenas as primeiras cinco instâncias dos conjuntos de dados \emph{Cr.Ger} e \emph{Cr.Aust}. Eles possuem 1000 e 650 instâncias, respectivamente}.

\vspace{0.5cm}
\begin{lstlisting}[caption=Formato original dos dados (\emph{Cr.Ger}), label=lst:dev_data_ger]
A11 6 A34 A43 1169 A65 A75 4 A93 A101 4 A121 67 A143 A152 2 A173 1 A192 A201 1
A12 48 A32 A43 5951 A61 A73 2 A92 A101 2 A121 22 A143 A152 1 A173 1 A191 A201 2
A14 12 A34 A46 2096 A61 A74 2 A93 A101 3 A121 49 A143 A152 1 A172 2 A191 A201 1
A11 42 A32 A42 7882 A61 A74 2 A93 A103 4 A122 45 A143 A153 1 A173 2 A191 A201 1
A11 24 A33 A40 4870 A61 A73 3 A93 A101 4 A124 53 A143 A153 2 A173 2 A191 A201 2
\end{lstlisting}
\vspace{0.5cm}

\vspace{0.5cm}
\begin{lstlisting}[caption=Formato original dos dados (\emph{Cr.Aust}), label=lst:dev_data_aust]
1 22.08 11.46 2 4 4 1.585 0 0 0 1 2 100 1213 0
0 22.67 7 2 8 4 0.165 0 0 0 0 2 160 1 0
0 29.58 1.75 1 4 4 1.25 0 0 0 1 2 280 1 0
0 21.67 11.5 1 5 3 0 1 1 11 1 2 0 1 1
1 20.17 8.17 2 6 4 1.96 1 1 14 0 2 60 159 1
\end{lstlisting}
\vspace{0.5cm}

A preparação dos dados para a importação no WEKA consistiu na adição de uma seção de cabeçalho e da formatação dos dados para valores separados por vírgula (seção \ref{sec:prop_arff}) e o resultado é mostrado nas listagens \ref{lst:dev_arff_ger} e \ref{lst:dev_arff_aust} (essas listagens mostram apenas as primeiras cinco instâncias na seção de dados).

\vspace{0.5cm}
\begin{lstlisting}[caption=Arquivo ARFF do \emph{Cr.Ger}, label=lst:dev_arff_ger]
@relation cr.ger

@attribute A1  {A11,A12,A13,A14}
@attribute A2  numeric
@attribute A3  {A30,A31,A32,A33,A34}
@attribute A4  {A40,A41,A42,A43,A44,A45,A46,A47,A48,A49,A410}
@attribute A5  numeric
@attribute A6  {A61,A62,A63,A64,A65}
@attribute A7  {A71,A72,A73,A74,A75}
@attribute A8  numeric
@attribute A9  {A91,A92,A93,A94,A95}
@attribute A10 {A101,A102,A103}
@attribute A11 numeric
@attribute A12 {A121,A122,A123,A124}
@attribute A13 numeric
@attribute A14 {A141,A142,A143}
@attribute A15 {A151,A152,A153}
@attribute A16 numeric
@attribute A17 {A171,A172,A173,A174}
@attribute A18 numeric
@attribute A19 {A191,A192}
@attribute A20 {A201,A202}
@attribute A21 {1,2}

@data
A11,6,A34,A43,1169,A65,A75,4,A93,A101,4,A121,67,A143,A152,2,A173,1,A192,A201,1
A12,48,A32,A43,5951,A61,A73,2,A92,A101,2,A121,22,A143,A152,1,A173,1,A191,A201,2
A14,12,A34,A46,2096,A61,A74,2,A93,A101,3,A121,49,A143,A152,1,A172,2,A191,A201,1
A11,42,A32,A42,7882,A61,A74,2,A93,A103,4,A122,45,A143,A153,1,A173,2,A191,A201,1
A11,24,A33,A40,4870,A61,A73,3,A93,A101,4,A124,53,A143,A153,2,A173,2,A191,A201,2
\end{lstlisting}
\vspace{0.5cm}

\vspace{0.5cm}
\begin{lstlisting}[caption=Arquivo ARFF do \emph{Cr.Aust}, label=lst:dev_arff_aust]
@relation cr.aust

@attribute A1  {0,1}
@attribute A2  numeric
@attribute A3  numeric
@attribute A4  {1,2,3}
@attribute A5  {1,2,3,4,5,6,7,8,9,10,11,12,13,14}
@attribute A6  {1,2,3,4,5,6,7,8,9}
@attribute A7  numeric
@attribute A8  {1,0}
@attribute A9  {1,0}
@attribute A10 numeric
@attribute A11 {1,0}
@attribute A12 {1,2,3}
@attribute A13 numeric
@attribute A14 numeric
@attribute A15 {0,1}

@data
1,22.08,11.46,2,4,4,1.585,0,0,0,1,2,100,1213,0
0,22.67,7,2,8,4,0.165,0,0,0,0,2,160,1,0
0,29.58,1.75,1,4,4,1.25,0,0,0,1,2,280,1,0
0,21.67,11.5,1,5,3,0,1,1,11,1,2,0,1,1
1,20.17,8.17,2,6,4,1.96,1,1,14,0,2,60,159,1
\end{lstlisting}
\vspace{0.5cm}

Com os arquivos no formato ARFF, os conjuntos de dados podem ser importados no WEKA. A figura \ref{fig:dev_weka_arff} mostra o conjunto de dados \emph{Cr.Ger} quando importado. Um conjunto de dados importado pode ser utilizado para qualquer algoritmo que suporte os tipos de atributos contidos nele.

\begin{figure}[h!]
    \vspace{0.5cm}
    \centering
    \caption{Conjunto de dados \emph{Cr.Ger importado no WEKA}}
    \label{fig:dev_weka_arff}
    \vspace{0.5cm}
    \includegraphics[width=0.75\textwidth]{img/cr_ger.png}
    \vspace{0.5cm}
    \vspace{0.5cm}
\end{figure}

\section{Utilizando o WEKA}

O WEKA é dividido em dois módulos principais: Explorer e Experimenter. Além disso, o WEKA apresenta duas interfaces principais: linha de comando (\emph{command-line interface}, CLI\nomenclature{CLI}{Command-line Interface}) e gráfica (\emph{graphical user interface}, GUI\nomenclature{GUI}{Graphical User Interface}). A interface gráfica é mais apropriada para exploração e experimentação, e para a apresentação dos dados, algoritmos e resultados. A interface de linha de comando é mais apropriada para automatização de tarefas e integração com outros sistemas, além de consumir menos recursos. Os dois módulos podem ser usados em qualquer uma das duas interfaces, com as mesmas funcionalidades.

Nesse trabalho foi utilizado o módulo \emph{Experimenter} na interface por linha de comando. O módulo \emph{Experimenter} tem um formato de arquivo de configuração que facilita a definição de experimentos e a repetição e automação dos testes para cada algoritmo usando a interface por linha de comando é muito mais fácil do que se fosse utilizada a interface gráfica. Os exemplos de execução são apresentados conforme devem ser digitados em uma interface de linha de comando, em um emulador de terminal, utilizando um \emph{shell} como \emph{sh} ou \emph{bash}.

\subsection{Filtros}
\label{sec:dev_weka_filters}

No WEKA, um filtro é um objeto que recebe um conjunto de dados como entrada e produz um conjunto de dados modificado. Esse é um processo comum da Mineração de Dados, chamado de pré-processamento dos dados: adicionar, remover ou alterar atributos, etc.

Um filtro comum, que é utilizado nesse trabalho, é o de criação de partições para o \emph{cross-validation}. Para esse filtro, são passados três argumentos. O argumento \emph{c} indica qual dos atributos é o atributo correspondente à classe, e é representado por um índice, iniciado em 1, conforme a declaração na seção de atributos do arquivo de dados (caso o padrão do WEKA seja usado, ou seja, o atributo de classe seja o último da listagem, pode ser utilizado o valor ``\emph{last}'' como argumento). O argumento \emph{N} indica o número de partições, e o argumento \emph{F} indica o índice da partição selecionada.

Além desses, o argumento \emph{V} pode ser utilizado para gerar o conjunto inverso de seleções, útil para dividir o conjunto em duas partes complementares. Dessa forma, para gerar um conjunto de dados para testes e outro para treinamento, podem ser usados comandos como os da listagem \ref{lst:dev_filter}\footnote{Nesses exemplos, é usado o redirecionamento de entrada e saída presentes na maioria dos \emph{shells} UNIX. O caractere ``<'' seguido de um nome de arquivo indica que aquele arquivo será usado como entrada para o comando. De maneira semelhante, o caractere ``>'' seguido de um nome de arquivo indica que ele será usado como saída. O WEKA também permite que sejam utilizadas as opções \emph{i} e \emph{o}, respectivamente, para obter os mesmos resultados. No primeiro exemplo, a forma equivalente seria ``\emph{-i dataset.arff -o dataset\_test.arff}''.}. Nesse exemplo, são o conjunto de dados é dividido em quatro partições, conforme indicado pelo argumento N. Na primeira linha, a primeira partição é escolhida, conforme indicado pelo argumento F. Na segunda, todas as partições com exceção da primeira são selecionadas, conforme indicado pelo parâmetro V.

\begin{lstlisting}[caption=Filtro para geração de partições para \emph{cross-validation}, label=lst:dev_filter]
java weka.filters.supervised.instance.StratifiedRemoveFolds -c last -N 4 -F 1 \
    < dataset.arff > dataset_test.arff
java weka.filters.supervised.instance.StratifiedRemoveFolds -c last -N 4 -F 1 -V \
    < dataset.arff > dataset_train.arff
\end{lstlisting}

\subsection{Execução de um classificador}

A execução de um algoritmo é feita através da classe que implementa o algoritmo no WEKA. Diversas opções podem ser passadas na linha de comando para mudar os parâmetros do algoritmo. Existem algumas opções adicionais para especificar dados adicionais, como os arquivos de dados para treinamento e testes. Além das opções gerais, cada algoritmo pode aceitar diferentes tipo de opções específicas. Como exemplo, para gerar a saída da listagem \ref{lst:prop_weka_out}, foi utilizado o comando da listagem \ref{lst:dev_exec_classifier}.

\vspace{0.5cm}
\begin{lstlisting}[caption=Execução de um classificador, label=lst:dev_exec_classifier]
java weka.classifiers.neural.lvq.Lvq1 -t data/weather.numeric.arff -i
\end{lstlisting}
\vspace{0.5cm}

Como é possível ver, a linha de comando é reproduzida no atributo ``\emph{Scheme}'' na saída. Esse atributo pode ser consultado para executar exatamente o mesmo teste novamente, tornando a reprodução do experimento muito mais fácil. As diversas opções do atributo que não estão presentes na linha de comando são os parâmetros do algoritmo. Como não foram especificados na linha de comando, foram assumidos os valores padrão, que são mostrados na saída. As duas opções que não estão presentes na saída são a opção ``\emph{i}'', que mostra uma saída mais completa e a opção ``\emph{t}'', que indica o arquivo que será utilizado como entrada.

Para executar os algoritmos do pacote de algoritmos imunológicos, é necessário informar à máquina virtual a localização do arquivo que contém o código executável. Esse código é disponibilizado em um arquivo \emph{jar}, um tipo de arquivo específico da linguagem java que é semelhante a um arquivo compactado utilizando os programas \emph{tar} ou \emph{zip}.

Para indicar o arquivo, é utilizada a opção \emph{classpath} da máquina virtual. Essa opção pode ser utilizada tanto para indicar um diretório contendo os arquivos compilados (arquivos \emph{.class}) quanto um arquivo \emph{jar}. Alternativamente, o arquivo \emph{jar} pode ser descompactado e o diretório gerado utilizado. Essa opção pode ser passada na linha de comando ou como uma variável de ambiente. Para executar o algoritmo AIRS, por exemplo, é utilizado qualquer um dos comandos da listagem \ref{lst:dev_weka_airs}. A sintaxe da opção \emph{classpath} é semelhante ao \emph{path} da maioria dos sistemas operacionais, ou seja, uma lista dos caminhos e arquivos separados pelo caractere ``:'' (dois-pontos) em sistemas Unix ou ``;'' (ponto-e-vírgula) em sistemas Windows.

\vspace{0.5cm}
\begin{lstlisting}[caption=Execução de um algoritmo do pacote de algoritmos imunológicos, label=lst:dev_weka_airs]
# Opção na linha de comando.
java -classpath wekaclassalgos.jar weka.classifiers.immune.airs.AIRS1 # parâmetros
# Variável de ambiente.
CLASSPATH=wekaclassalgos.jar
java weka.classifiers.immune.airs.AIRS1 # parâmetros
\end{lstlisting}
\vspace{0.5cm}

Combinando os conceitos apresentados nessa seção, a execução de um teste para um algoritmo imunológico utilizando um dos conjuntos de dados é feita de acordo com a listagem \ref{lst:dev_weka_single}. Aqui, é usado a opção ``\emph{t}'' para especificar o conjunto de dados \emph{Cr.Ger}. Todas as outras opções são parâmetros do filtro (os valores utilizados são os valores padrão para esse algoritmo).

\vspace{0.5cm}
\begin{lstlisting}[caption=Execução de um algoritmo do pacote de algoritmos imunológicos utilizando um dos conjuntos de dados, label=lst:dev_weka_single]
# Variável de ambiente.
CLASSPATH=wekaclassalgos.jar
java weka.classifiers.immune.airs.AIRS1 \
    -S 1 -F 0.2 -C 10.0 -H 2.0 -M 0.1 -R 150.0 -V 0.9 -A -1 -B 1 -E 1 -K 3 \
    -t german.arff
\end{lstlisting}
\vspace{0.5cm}

\subsection{Execução dos classificadores}

Para a execução de um teste, pode ser criado um executor genérico de classificadores, com base na listagem \ref{lst:dev_weka_template}:

\vspace{0.5cm}
\begin{lstlisting}[caption=Execução genérica de um classificador, label=lst:dev_weka_template]
# Variável de ambiente.
java -classpath "$classpath" \
    "$classificador" "$parametros" -t "$conjunto_de_dados" \
    > "$arquivo_resultados"
\end{lstlisting}
\vspace{0.5cm}

Dessa forma, é possível utilizar o mesmo comando para execução, variando apenas os valores das variáveis. Os valores utilizados para cada variável foram:

\begin{enumerate}[a)]
    \item \emph{classpath}: conforme explicado na sessão anterior. Esse valor não muda entre as execuções dos testes, mas é mantido como uma variável para que ele possa ser facilmente alterado caso necessário. Esse é o arquivo \emph{jar} do WEKA que contém a implementação dos algoritmos imunológicos (\emph{wekaclassalgos.jar}). Esse arquivo também contém os algoritmos do WEKA, então ele é a única dependência necessária para utilizar os classificadores imunológicos e os que já são incluídos no WEKA.
    \item \emph{classificador}: todos os classificadores testados no experimento:
        \begin{enumerate}[a)]
            \item weka.classifiers.immune.airs.AIRS2
            \item weka.classifiers.immune.immunos.Immunos99
            \item weka.classifiers.immune.clonalg.CLONALG
            \item weka.classifiers.functions.MultilayerPerceptron
            \item weka.classifier.functions.SMO
            \item weka.classifiers.meta.AttributeSelectedClassifier
            \item weka.classifiers.trees.J48
            \item weka.classifiers.neural.lvq.Lvq2\_1
        \end{enumerate}
    \item \emph{parâmetros}: os parâmetros são listados junto com cada classificador no arquivo de configuração.
    \item \emph{conjunto\_de\_dados}: o caminho para o arquivo ARFF dos dois conjuntos de dados utilizados.
    \item \emph{arquivo\_resultados}: arquivo onde os resultados são gravados.
\end{enumerate}

\subsection{Seleção de parâmetros no WEKA}

Conforme descrito no capítulo \ref{chap:eval}, o desempenho de um algoritmo depende da escolha dos parâmetros utilizados. Como o processo de escolha de parâmetros é repetitivo e fácil de ser automatizado, existem métodos para escolher os parâmetros que geram o melhor valor para os parâmetros de um modelo para um conjunto de dados específico. Um desses métodos, muito utilizado por sua simplicidade e eficácia (embora não seja tão eficiente), é o \emph{grid search}.

No WEKA, existem duas implementações desse método. Ambos fazem parte de uma categoria denominada \emph{meta-classificadores}\footnote{Esses e outros meta-classificadores que o WEKA disponibiliza podem ser encontrados no pacote \emph{weka.classifiers.meta}.}, ou seja, classificadores que atuam sobre a execução de outros classificadores. Esses dois componentes são \emph{GridSearch} e \emph{CVParameterSelection}, e seu funcionamento é semelhante. O processo para utilizá-los para a escolha de parâmetros é o seguinte:

\begin{enumerate}[a)]
    \item Indicar o meta-classificador utilizado.
    \item Indicar o classificador real que será utilizado.
    \item Listar os parâmetros que serão testados.
    \item Listar a faixa de valores para os parâmetros.
    \item Indicar o conjunto de dados que será utilizado.
    \item Executar o teste.
\end{enumerate}

Com exceção dos itens \emph{a)} e \emph{d)}, o processo é semelhante à execução de um classificador comum. De fato, o meta-classificador executará o classificador da mesma forma que o WEKA faria. No entanto, ao invés de um única execução com parâmetros fixos, esses dois meta-classificadores fazem diversos testes, utilizando todas as combinações possíveis dos valores listados no item \emph{d)} para os parâmetros.

É importante levar em consideração que, conforme discutido anteriormente, esse processo é de grande utilidade para determinar os melhores valores para os parâmetros do classificador, no entanto, uma óbvia desvantagem é o grande aumento no tempo de execução. O número de combinações possíveis cresce exponencialmente com o número de parâmetros e número de elementos na faixa de valores para esses parâmetros.

Existem formas de amenizar o efeito da explosão combinatória desses métodos. A opção mais popular aproveita o grande potencial de paralelização do processo de execução do classificador com diferentes parâmetros. Como cada execução é completamente independente das outras, e podem ser executadas em paralelo. Na prática, grandes quantidades de unidades de processamento (denominados \emph{clusters}) são utilizados, e conjuntos de combinações de valores são distribuídas para cada um. Dessa forma, é possível aproveitar ao máximo a quantidade de recursos disponíveis. Os resultados dos testes podem então ser combinados em uma única unidade para a análise final.

\section{\emph{Experimenter}}

Além do módulo \emph{Explorer}, para execução de testes, o WEKA apresenta um módulo para configuração e execução de experimentos, chamado \emph{Experimenter} (figura \ref{fig:dev_weka_experimenter}). Esse módulo facilita a criação de experimentos, criando um arquivo de configuração onde são descritas as etapas, que pode ser utilizado para reproduzir o experimento usando as mesmas configurações.

\begin{figure}[h!]
    \vspace{0.5cm}
    \centering
    \caption{Experimenter}
    \label{fig:dev_weka_experimenter}
    \vspace{0.5cm}
    \includegraphics[width=0.75\textwidth]{img/experimenter.png}
    \vspace{0.5cm}
    \vspace{0.5cm}
\end{figure}

A configuração do \emph{Experimenter} pode ser dividida nas seções:

\begin{enumerate}
    \item \textbf{Entrada}: a fonte do conjunto de dados. O padrão do WEKA é utilizar arquivos ARFF, mas todos os tipos de arquivos suportados podem ser usados, como arquivos CSV. Também é possível utilizar mais de um conjunto de dados para o mesmo experimento.
    \item \textbf{Tipo de experimento}: \emph{cross-validation} ou divisão fixa em dados de treino e teste.
    \item \textbf{Iterações}: número de execuções do experimento.
    \item \textbf{Algoritmos}: os algoritmos que serão testados. É possível configurar o parâmetros de cada algoritmo exatamente como é feito no \emph{Explorer}.
    \item \textbf{Saída}: o local onde os resultados do experimento serão gravados. O padrão é um arquivo CSV, mas outros tipos podem ser usados, com arquivos ARFF ou bancos de dados.
\end{enumerate}

Essas configurações podem ser gravadas em um arquivo para que possam ser reutilizadas. O formato desse arquivo pode ser tanto uma representação em formato binário exclusiva do WEKA ou um arquivo CSV.

A partir de um arquivo de configuração é possível executar um experimento usando a interface gráfica. Também é possível utilizar a interface de linha de comando, conforme a listagem \ref{lst:dev_run_experiment}.

\vspace{0.5cm}
\begin{lstlisting}[caption=Execução de um experimento, label=lst:dev_run_experiment]
# Flags:
#     -l: indica o arquivo de configuração (load).
#     -r: executar o experimento (run).
java weka.experiment.Experiment -l exp.xml -r
\end{lstlisting}
\vspace{0.5cm}

\subsection{Resultados}

Conforme mencionado acima, o formato padrão de gravação dos resultados de um experimento pelo \emph{Experimenter} é em arquivos CSV. É gerada uma linha no arquivo com as informações e resultados a cada execução. O número de linha gerado é igual ao número de execuções na configuração do experimento, multiplicado pelo número de \emph{folds} usado no \emph{cross-validation} (caso essa opção tenha sido selecionada), multiplicado pelo número de conjuntos de dados (que pode ser apenas um). Dessa forma, caso o número de execuções seja configurado como "10", o número de \emph{folds} como "10" e sejam utilizados dois conjuntos de dados, serão geradas 200 linhas de resultados no arquivo de saída.

Para cada execução são gravados dados sobre os resultados do treinamento e da classificação das instâncias. Esses dados são os mesmos exibidos quando uma classificação é executada usando o módulo \emph{Explorer} (listagem \ref{lst:prop_weka_out}). Uma lista completa das variáveis é mostrada na listagem \ref{lst:dev_experimenter_header}.

\vspace{0.5cm}
\begin{lstlisting}[caption=Variáveis gravados pelo \emph{Experimenter}, label=lst:dev_experimenter_header]
Key_Dataset
Key_Run
Key_Fold
Key_Scheme
Key_Scheme_options
Key_Scheme_version_ID
Date_time
Number_of_training_instances
Number_of_testing_instances
Number_correct
Number_incorrect
Number_unclassified
Percent_correct
Percent_incorrect
Percent_unclassified
Kappa_statistic
Mean_absolute_error
Root_mean_squared_error
Relative_absolute_error
Root_relative_squared_error
SF_prior_entropy
SF_scheme_entropy
SF_entropy_gain
SF_mean_prior_entropy
SF_mean_scheme_entropy
SF_mean_entropy_gain
KB_information
KB_mean_information
KB_relative_information
True_positive_rate
Num_true_positives
False_positive_rate
Num_false_positives
True_negative_rate
Num_true_negatives
False_negative_rate
Num_false_negatives
IR_precision
IR_recall
F_measure
Area_under_ROC
Weighted_avg_true_positive_rate
Weighted_avg_false_positive_rate
Weighted_avg_true_negative_rate
Weighted_avg_false_negative_rate
Weighted_avg_IR_precision
Weighted_avg_IR_recall
Weighted_avg_F_measure
Weighted_avg_area_under_ROC
Elapsed_Time_training
Elapsed_Time_testing
UserCPU_Time_training
UserCPU_Time_testing
Serialized_Model_Size
Serialized_Train_Set_Size
Serialized_Test_Set_Size
Summary
\end{lstlisting}
\vspace{0.5cm}

Essas variáveis contém informações sobre o conjunto de dados (nome e número de instâncias de treinamento e testes), classificador (nome e parâmetros), sobre o processo de treinamento e classificação (data, tempo de execução e consumo de memória) e sobre os resultados (diversas medidas de eficácia).

\section{Seleção de algoritmos}

Todos os algoritmos utilizados para comparação com os algoritmos imunológicos fazem parte da distribuição padrão do WEKA (a versão utilizada é a 3.6.9 de 25 de janeiro de 2013). A figura \ref{fig:dev_weka_algos} mostra os algoritmos na listagem de classificadores do WEKA. Os algoritmos serão descritos brevemente nas próximas seções.

\iffalse add value of default parameters \fi

\begin{figure}[h]
    \vspace{0.5cm}
    \centering
    \caption{Algoritmos no WEKA}
    \label{fig:dev_weka_algos}
    \vspace{0.5cm}
    \includegraphics[height=0.5\textheight]{img/weka_algos_cropped.png}
    \vspace{0.5cm}
\end{figure}

Esses algoritmos podem ser dividos em 5 categorias de algoritmos: árvores de decisão, redes neurais artificiais, redes Bayesianas, \emph{support vector machine} e imunológicos. Na tabela \ref{tbl:dev_algs} são apresentados os mesmo algoritmos, organizados pela categoria a que pertencem.

\begin{table}[h]
    \vspace{0.5cm}
    \centering
    \caption{Algoritmos utilizados para comparação}
    \label{tbl:dev_algs}
    \vspace{0.5cm}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Categoria}                         & \textbf{Algoritmos}                    \\
        \hline
        \multirow{2}{*}{Árvores de decisão}        & ID3                                    \\ \cline{2-2}
                                                   & C4.5 (J48)                             \\
        \hline
        \multirow{2}{*}{Redes neurais artificiais} & Multilayer Perceptron                  \\ \cline{2-2}
                                                   & Learning Vector Quantization (Lvq2\_1) \\
        \hline
        \multirow{2}{*}{Redes Bayesianas}          & Naive Bayes                            \\ \cline{2-2}
                                                   & Bayes Net                              \\
        \hline
        Support Vector Machine                     & Sequential Minimal Optimization        \\
        \hline
        \multirow{3}{*}{Imunológicos}              & AIRS                                   \\ \cline{2-2}
                                                   & Immunos                                \\ \cline{2-2}
                                                   & Seleção Clonal (CLONALG)               \\
        \hline
    \end{tabular}
    \vspace{0.5cm}
\end{table}

\subsection{Redes neurais artificiais}

Um algoritmo que utiliza uma rede de neurônios artificiais inspirados no modelo dos neurônios biológicos do sistema nervoso. Simula uma rede de neurônios usando um modelo computacional baseado nas conexões entre os neurônios.

\subsubsection{MultilayerPerceptron}

Uma implementação de uma rede neural multicamadas que usa o algoritmo \emph{backpropagation}, proposto por Paul Werbos \cite{Werbos1974}. A aprendizagem acontece através de repetidas iterações e ajustes dos pesos das conexões entre neurônios. Pode ser treinada de forma automática, mas o WEKA oferece uma interface onde os pesos da rede podem ser alterados manualmente.

\begin{enumerate}[a)]
    \item \textbf{Parâmetros}:
        \begin{itemize}
            \item \textbf{L}: taxa de aprendizagem.
            \item \textbf{M}: taxa de \emph{momentum}.
            \item \textbf{N}: número de \emph{epochs} (uma iteração do processo de treinamento e teste).
            \item \textbf{V}: tamanho do conjunto de validação do treinamento.
            \item \textbf{S}: semente do gerador de números aleatórios.
            \item \textbf{E}: número máximo de erros consecutivos para término da validação da rede.
            \item \textbf{G}: abre a interface de criação da rede.
            \item \textbf{A}: não cria as conexões da rede.
            \item \textbf{B}: não aplica o filtro NominalToBinary.
            \item \textbf{H}: parâmetro para configuração das camadas escondidas da rede.
            \item \textbf{C}: desabilita a aplicação de normalização no atributo de classe.
            \item \textbf{I}: desabilita a aplicação de normalização em todos os atributos.
            \item \textbf{R}: desabilita a reinicialização da rede durante o treinamento.
            \item \textbf{D}: habilita a diminuição gradual da taxa de aprendizagem.
        \end{itemize}
    \item \textbf{Parâmetros testados}:
        \begin{itemize}
            \item \textbf{L}: 0.1, 0.2, 0.3, 0.4, 0.5.
        \end{itemize}
\end{enumerate}

\subsection{Árvores de decisão}

Algoritmo supervisionado que monta uma árvore ligando observações sobre os dados à conclusões sobre esses dados. É um tipo de algoritmo preditivo muito usado em sistemas especialistas e aprendizagem de máquina por gerar um modelo que pode ser facilmente analisado e ajustado.

\subsubsection{ID3}

Algoritmo de árvores de decisão usado em aprendizagem de máquina, desenvolvido por Ross Quinlan \cite{Quinlan1986}. Divide conjunto de atributos dos dados em subconjuntos iterativamente, separando sempre pelo atributo com menor entropia (maior ganho de informação).

\begin{enumerate}[a)]
    \item \textbf{Parâmetros}: esse algoritmo não aceita parâmetros.
    \item \textbf{Filtros}: como o ID3 não suporta atributos numéricos, foi necessário discretizar os valores numéricos (seção \ref{sec:dev_weka_filters}).
\end{enumerate}

\subsubsection{C4.5}

Uma extensão do algoritmo ID3, desenvolvido pelo mesmo autor \cite{Quinlan1993}. Entre as melhorias do algoritmo estão o tratamento mais eficiente de dados contínuos, o tratamento a dados incompletos e a poda da árvore após o treinamento. O WEKA tem uma implementação \emph{open source} desse algoritmo chamado J48.

\begin{enumerate}[a)]
    \item \textbf{Parâmetros}:
        \begin{itemize}
            \item \textbf{U}: usa uma árvore sem poda.
            \item \textbf{C}: limiar de confiança para poda.
            \item \textbf{M}: número mínimo de instâncias por folha.
            \item \textbf{R}: reduz o número de instâncias usadas na poda pós-execução.
            \item \textbf{N}: número de partições para a poda pós-execução.
            \item \textbf{B}: realiza apenas divisões binárias em atributos numéricos, ao invés de divisões de tamanho arbitrário.
            \item \textbf{S}: desativa a poda baseada em elevação de ramos da árvore.
            \item \textbf{L}: desativa o processo de otimização de memória.
            \item \textbf{A}: aplica o algoritmo de suavização de Laplace às probabilidades da árvore.
            \item \textbf{Q}: semente do gerador de números aleatórios.
        \end{itemize}
    \item \textbf{Parâmetros testados}:
        \begin{itemize}
            \item \textbf{C}: 0.1, 0.2, 0.3, 0.4, 0.5.
            \item \textbf{M}: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10.
        \end{itemize}
\end{enumerate}

\subsection{Learning Vector Quantization (LVQ)}

Algoritmo de classificação baseado no \emph{Vector Quantization} (\emph{VQ}), um algoritmo que distribui as instâncias no espaço de estados e iterativamente aproxima as instâncias semelhantes, até que sejam formados \emph{clusters} com as instâncias classificadas \cite{Kohonen1997}.

\subsubsection{Lvq2\_1}

Algoritmo presente no pacote de algoritmos de Jason Bronwlee. Uma implementação do algoritmo LVQ onde duas instâncias são analisadas a cada iteração, sendo atualizadas quando uma pertence à classe desejada e a outra não e a distância se encontra dentro de uma faixa pré-definida \cite{Brownlee2011w}.

\begin{enumerate}[a)]
    \item \textbf{Parâmetros}:
        \begin{itemize}
            \item \textbf{M}: modo de inicialização dos vetores.
            \item \textbf{L}: tipo de função para a taxa de aprendizagem.
            \item \textbf{R}: valor inicial da taxa de aprendizagem.
            \item \textbf{C}: número total de vetores no modelo.
            \item \textbf{I}: número total de iterações.
            \item \textbf{G}: seleção dinâmica da classe de cada instância.
            \item \textbf{W}: limiar de semelhança entre as instâncias comparadas.
        \end{itemize}
    \item \textbf{Parâmetros testados}:
        \begin{itemize}
            \item \textbf{R}: 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0.
            \item \textbf{W}: 0.1, 0.2, 0.3, 0.4, 0.5.
        \end{itemize}
\end{enumerate}

\subsection{Redes Bayesianas}

Um modelo probabilístico desenvolvido usando os modelos derivados do teorema de Bayes \cite{Bayes1763}. O modelo gerado tem a forma de um grafo direcionado acíclico, onde os nodos são variáveis e as arestas as dependências condicionais entre elas \cite{Pearl1988}.

\subsubsection{Naive Bayes}

Um classificador que cria redes bayesianas simples, onde cada atributo do conjunto de dados é analisado independentemente do outro. O resultado é um modelo onde os atributos não influenciam uns aos outros. Por causa dessa limitação, o treinamento desse algoritmo é muito eficiente.

\begin{enumerate}[a)]
    \item \textbf{Parâmetros}:
        \begin{itemize}
            \item \textbf{K}: usa Kernel Density Estimator ao invés de distribuição normal para atributos numéricos.
            \item \textbf{D}: usa discretização supervisionada para processar atributos numéricos.
        \end{itemize}
\end{enumerate}

\subsubsection{Bayes Net}

Implementação do algoritmo padrão de redes bayesianas. Permite a escolha da medida de avaliação e do método de busca no espaço de estados utilizados pelo classificador.

\begin{enumerate}[a)]
    \item \textbf{Parâmetros}:
        \begin{itemize}
            \item \textbf{D}: utiliza ADTree, aumentado a velocidade de treinamento mas consumindo mais recursos.
            \item \textbf{Q}: método para busca na rede.
            \item \textbf{E}: método para encontrar as tabelas de probabilidade condicional.
        \end{itemize}
    \item \textbf{Filtros}: \emph{weka.filter.supervised.attribute.Discretize}.
\end{enumerate}

\subsection{Support Vector Machine (SVM)}

Esse classificador considera as instâncias como pontos em um espaço de estados e tenta traçar uma linha que separe esses pontos em duas regiões do espaço. Por isso, é considerado um classificador binário linear. Classifica uma nova instância posicionando-a no espaço de estados e identificando em que lado da linha separadora essa instância se encontra \cite{Cortes1995}.

\subsubsection{Sequential Minimal Optimization (SMO)}

Algoritmo iterativo para o problema da otimização de uma máquina de vetor de suporte. A implementação do WEKA é baseada no algoritmo por John Platt \cite{Platt1998}.

\begin{enumerate}[a)]
    \item \textbf{Parâmetros}:
        \begin{itemize}
            \item \textbf{C}: a constante de complexidade das regras de decisão.
            \item \textbf{N}: opção para normalizar, uniformizar ou usar os dados oringinais.
            \item \textbf{L}: o parâmetro de tolerância.
            \item \textbf{P}: \emph{epsilon} para erro de arredondamento.
            \item \textbf{M}: aplica regressão logística aos pesos.
            \item \textbf{W}: número de partições para o \emph{cross-validation} interno.
            \item \textbf{K}: o \emph{kernel} que será utilizado.
        \end{itemize}
    \item \textbf{Parâmetros testados}:
        \begin{itemize}
            \item \textbf{C}: 1, 2, 3, 4, 5.
        \end{itemize}
\end{enumerate}

\subsection{Algoritmos imunológicos}

\iffalse intro \fi

\subsubsection{AIRS}

\begin{enumerate}[a)]
    \item \textbf{Parâmetros}:
        \begin{itemize}
        \item \textbf{F}: controla o limiar de afinidade para substituição de células de memória.
        \item \textbf{C}: taxa de clonagem.
        \item \textbf{H}: taxa de hiper-mutação.
        \item \textbf{K}: número de células de memória usadas durante a classificação de novas instâncias.
        \item \textbf{E}: número inicial de células de memória.
        \item \textbf{A}: número de células usadas no cálculo do limiar de afinidade.
        \item \textbf{V}: limite para o refinamento das células de memória.
        \item \textbf{R}: número máximo de células.
        \end{itemize}
\end{enumerate}

\subsubsection{Immunos}

\begin{enumerate}[a)]
    \item \textbf{Parâmetros}:
        \begin{itemize}
            \item \textbf{G}: número de gerações.
            \item \textbf{E}: limiar mínimo de afinidade.
            \item \textbf{S}: porcentagem de cada grupo de antígenos usada na inicialização da população de células B.
        \end{itemize}
    \item \textbf{Parâmetros testados}:
        \begin{itemize}
            \item \textbf{G}: 1, 2, 3, 4.
        \end{itemize}
\end{enumerate}

\subsubsection{CLONALG}

\begin{enumerate}[a)]
    \item \textbf{Parâmetros}:
        \begin{itemize}
            \item \textbf{N}: tamanho do \emph{pool} de anticorpos.
            \item \textbf{B}: taxa de clonagem.
            \item \textbf{G}: número de gerações.
            \item \textbf{R}: número de anticorpos mantidos entre cada geração.
            \item \textbf{n}: número de anticorpos selecionado para clonagem e mutação a cada geração.
            \item \textbf{d}: número de anticorpos descartado e substituído a cada geração.
        \end{itemize}
\end{enumerate}

\section{Problemas encontrados}
\label{sec:dev_weka_issues}

Durante a preparação e execução dos testes, dois problemas principais foram encontrados, ambos no pacote de algoritmos imunológicos usado. Apesar de nenhum impedir a conclusão do trabalho, ambos são dignos de nota.

O primeiro foi um problema na definição dos parâmetros do CLONALG. Como foi mostrado no capítulo \ref{chap:prop}, o WEKA permite a passagem de diversas opções na linha de comando para alterar o seu modo de funcionamento. Essas opções são na forma de \emph{flags}, como é padrão em interfaces de linha de comando. Um desses parâmetros é usado para indicar que o modelo previamente gerado deve ser lido de um arquivo, ao invés de criado novamente (a listagem \ref{lst:dev_weka_d_param} mostra a definição do parâmetro pelo próprio WEKA).

\vspace{0.5cm}
\begin{lstlisting}[caption=Definição do parâmetro ``d'' no wEKA, label=lst:dev_weka_d_param]
-d <name of output file>
    Sets model output file. In case the filename ends with '.xml',
    only the options are saved to the XML file, not the model.
\end{lstlisting}
\vspace{0.5cm}

No entanto, um dos parâmetros do CLONALG também usa a letra ``d'' como representação (conforme apresentado na seção anterior, o parâmetro é o número de anticorpos substituído a cada geração). Isso gerava um conflito na execução do algoritmo, já que as opções do WEKA são analisadas antes das opções do algoritmo. O resultado era uma mensagem de erro apontando que o parâmetro ``d'' não tinha sido passado.

Para solucionar esse problema, foi feita uma alteração diretamente no código do algoritmo. As opções do algoritmo são definidas em um vetor na linha 37 do arquivo src/weka/classifiers/immune/clonalg/CLONALG.java (listagem \ref{lst:dev_clonalg_source}). A alteração para a solução foi alterar o nome do parâmetro "d" para uma letra que não conflitasse com outros parâmetros do WEKA ou do algoritmo. Após isso, o código do WEKA foi compilado e essa versão alterada foi utilizada na execução dos testes.

\vspace{0.5cm}
\begin{lstlisting}[caption=Código fonte original do CLONALG, label=lst:dev_clonalg_source]
private final static String [] PARAMETERS = {
    "B", "N", "n", "d", "G", "S", "R"
};
\end{lstlisting}
\vspace{0.5cm}

O segundo problema encontrado foi no algoritmo AIRS. Conforme o trabalho de Jason Brownlee \cite{Brownlee2005}, a condição de parada do algoritmo é:

\begin{quote}
The stop condition for this process of ARB refinement occurs when the
mean normalised stimulation is more than the user defined stimulation
threshold.

[...]

Stimulation Threshold – As mentioned, the stopping criterion to the ARB
refinement process is when the mean normalised stimulation value is above
the stimulation threshold. This parameter controls the amount of refinement
performed on ARBs for an antigen, and thus how closely the ARBs will be
to the antigen in question. Stimulation values are commonly high, around
0.9. This means that the mean stimulation value must be quite high, that is
the vast majority of the ARBs in the pool must be similar to the antigen.
The range for the stimulation threshold must obviously be in the range of
[0,1], given the mean also will have the same range.
\end{quote}

Como pode ser visto, o algoritmo não tem um número de iterações definido. Como a maioria dos algoritmos inspirados no sistema imunológico, o algoritmo itera até que o sistema entre em equilíbrio. O parâmetro \emph{stimulation threshold} (limiar de similaridade) pode ser usado para tornar esse teste mais ou menos rigoroso, conforme a necessidade. Valores mais altos geram um modelo mais sensível, mas podem aumentar o tempo de treinamento.

Utilizando o valor padrão do parâmetro (0.9), os testes demoravam um tempo proibitivo para serem executados. Foram feitos testes utilizando vários valores, para determinar um valor que fosse aceitável dado o tempo disponível para a execução dos experimentos. Os resultados desses testes são mostrados na tabela \ref{tbl:dev_airs_times}. Cada linha representa uma execução, onde o parâmetro \emph{stimulation threshold} assumiu o valor indicado e todos os outros tinham o valor padrão do algoritmo. Ao lado de cada linha, é mostrado o tempo de execução do teste.

\begin{table}[h]
    \vspace{0.5cm}
    \scriptsize
    \centering
    \caption{Tempo de execução dos testes do AIRS}
    \label{tbl:dev_exec_summary}
    \vspace{0.5cm}
    \begin{tabular}{c c}
        \textbf{Valor} & \textbf{Tempo de execução} \\
        \hline
        0.5            &  0m1.158s  \\
        0.75           &  0m2.148s  \\
        0.8            &  0m4.054s  \\
        0.85           &  0m14.263s \\
        0.875          &  0m27.451s \\
        0.8875         &  0m49.042s \\
        0.89375        &  2m52.582s \\
        0.896875       &  92m5.210s \\
    \end{tabular}
    \vspace{0.5cm}
\end{table}

O tempo de execução aumentava exponencialmente conforme o valor do parâmetro alcançava o valor padrão de 0.9. Por isso, para os testes, foi usado o valor 0.8 para esse parâmetro, que é baixo o suficiente para manter o tempo de execução em uma faixa aceitável mas alto o suficiente para não comprometer os resultados.

\section{Resultados}

Os testes foram executados para todos os algoritmos, usando as configurações descritas nas seções anteriores. A tabela \ref{tbl:dev_exec_summary} mostra um resumo das execuções. As colunas dessa tabela representam, da esquerda para a direita, a categoria do algoritmo, o algoritmo, o número de execuções do experimento, o número de \emph{folds} utilizado no \emph{cross-validation}, o número total de execuções do algoritmo e os parâmetros testados. Essa última coluna utiliza a sintaxe do \emph{CVParameterSelection} para descrição dos parâmetros, onde são indicados o nome do parâmetro, os valores mínimos e máximos que serão testados e o número de valores testados.

\begin{table}[h]
    \vspace{0.5cm}
    \scriptsize
    \centering
    \caption{Resumo das execuções}
    \label{tbl:dev_exec_summary}
    \vspace{0.5cm}
    \begin{tabular}{|l|c|c|c|c|c|c|c|c|}
        \hline
        \multirow{2}{*}{\textbf{Método}} & \multirow{2}{*}{\textbf{Algoritmo}} & \multirow{2}{*}{\textbf{Runs}} & \multirow{2}{*}{\textbf{Folds}} & \multirow{2}{*}{\textbf{Execuções}} & \multicolumn{4}{c|}{\textbf{Parâmetros testados}} \\
        \cline{6-9}
        & & & & & \textbf{Nome} & \textbf{Min.} & \textbf{Max.} & \textbf{n} \\
        \hline
        Redes neurais & MultilayerPerceptron & 10 & 10 & 200 & \multicolumn{4}{c|}{-} \\
        \hline
        \multirow{3}{*}{Árvores de decisão} & ID3 & 10 & 10 & 200 & \multicolumn{4}{c|}{-} \\
        \cline{2-9}
        & \multirow{2}{*}{J48} & \multirow{2}{*}{10} & \multirow{2}{*}{10} & \multirow{2}{*}{200} & M & 1 & 10 & 10 \\
        \cline{6-9}
        & & & & & C & 0.1 & 0.5 & 5 \\
        \hline
        \multirow{2}{*}{LVQ} & \multirow{2}{*}{Lvq2\_1} & \multirow{2}{*}{10} & \multirow{2}{*}{10} & \multirow{2}{*}{200} & R & 0.1 & 1 & 10 \\
        \cline{6-9}
        & & & & & W & 0.1 & 0.5 & 5 \\
        \hline
        \multirow{2}{*}{Redes bayesianas} & NaiveBayes & 10 & 10 & 200 & \multicolumn{4}{c|}{-} \\
        \cline{2-9}
        & BayesNet & 10 & 10 & 200 & \multicolumn{4}{c|}{-} \\
        \hline
        SVM & SMO & 10 & 10 & 200 & C & 1 & 5 & 5 \\
        \hline
        \multirow{4}{*}{Imunológicos} & AIRS & 10 & 10 & 200 & \multicolumn{4}{c|}{-} \\
        \cline{2-9}
        & Immunos & 1 & 10 & 20 & G & 1 & 4 & 4 \\
        \cline{2-9}
        & \multirow{2}{*}{CLONALG} & \multirow{2}{*}{10} & \multirow{2}{*}{10} & \multirow{2}{*}{200} & G & 5 & 20 & 4 \\
        \cline{6-9}
        & & & & & B & 0.1 & 0.5 & 5 \\
        \hline
    \end{tabular}
    \vspace{0.5cm}
\end{table}

Todos os testes foram executados em uma mesma máquina, serialmente, e a máquina não foi utilizada para nenhum outro processamento durante os testes. Isso foi feito para que não houvesse interferência externa ou interna nos resultados. As configurações da máquina relevantes para o experimento são mostradas na tabela \ref{tbl:dev_machine_specs}. É importante notar nesse tipo de experimento que é impossível isolar um sistema computacional completamente.

Uma técnica comumente usada é executar os testes repetidas vezes, escolhendo para comparação aquele que tiver o melhor resultado. Isso foi feito nesse trabalho através de uma funcionalidade do próprio módulo \emph{Experimenter} do WEKA, que permite configurar o número de execuções do experimento. Os resultados de todas as execuções são gravados no arquivo de saída e o melhor foi escolhido na coleta dos resultados.

Foi utilizado o código padrão presente na versão 3.6.1 do WEKA. As únicas exceções são as descritas na seção \ref{sec:dev_weka_issues}, mas essas alterações não têm impacto sobre a performance dos algoritmos.

\begin{table}[h]
    \vspace{0.5cm}
    \scriptsize
    \centering
    \caption{Configurações da máquina onde os testes foram executados}
    \label{tbl:dev_machine_specs}
    \vspace{0.5cm}
    \begin{tabular}{c c}
        \multicolumn{2}{c}{\textbf{Máquina de testes}}     \\
        \hline
        Tipo                & Máquina virtual (virtualbox) \\
        Sistema operacional & Ubuntu 12.04 LTS 32-bit      \\
        Processador         & Intel Pentium E2200 @2.20GHz \\
        Memória             & DDR2 800MHz 1024Mb           \\
    \end{tabular}
    \vspace{0.5cm}
\end{table}

\subsection{Resultados por conjunto de dados}

Nessa seção são apresentadas as tabelas com os resultados dos testes agrupados pelos conjuntos de dados (tabelas \ref{tbl:dev_table_first} à \ref{tbl:dev_table_last}). A separação por conjunto de dados facilita a comparação dos valores, já que há uma clara separação entre os resultados de cada um. A próxima seção faz uma análise dos resultados para cada algoritmo.

\begin{table}[h]
    \centering
    \caption{Porcentagem correta e error médio (cr.aust)}
    \label{tbl:dev_table_aust_correct}
    \label{tbl:dev_table_first}
    \vspace{0.5cm}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Algoritmo} & \textbf{Porcentagem correta} & \textbf{Erro quadrático médio} \\
        \hline
        \rowcolor[gray]{.9}
        J48                  & 95.65\% & 0.2364105060 \\ \hline
        \rowcolor[gray]{.9}
        MultilayerPerceptron & 94.20\% & 0.2497022089 \\ \hline
        \rowcolor[gray]{.9}
        BayesNet             & 94.20\% & 0.2264276254 \\ \hline
        SMO                  & 92.75\% & 0.2691909510 \\ \hline
        AIRS                 & 92.75\% & 0.2691909510 \\ \hline
        Immunos              & 91.30\% & 0.2948839123 \\ \hline
        NaiveBayes           & 88.41\% & 0.3021207800 \\ \hline
        ID3                  & 86.96\% & 0.3096584495 \\ \hline
        Lvq2\_1              & 79.71\% & 0.4504426165 \\ \hline
        CLONALG              & 76.81\% & 0.4815434123 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{Porcentagem correta e erro médio (cr.ger)}
    \label{tbl:dev_table_ger_correct}
    \vspace{0.5cm}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Algoritmo} & \textbf{Porcentagem correta} & \textbf{Erro quadrático médio} \\
        \hline
        \rowcolor[gray]{.9}
        NaiveBayes           & 84.00\% & 0.3655059498 \\ \hline
        \rowcolor[gray]{.9}
        BayesNet             & 84.00\% & 0.3553319820 \\ \hline
        \rowcolor[gray]{.9}
        SMO                  & 83.00\% & 0.4123105626 \\ \hline
        MultilayerPerceptron & 81.00\% & 0.4251917863 \\ \hline
        J48                  & 80.00\% & 0.3856184540 \\ \hline
        Lvq2\_1              & 76.00\% & 0.4898979486 \\ \hline
        Immunos              & 75.00\% & 0.5000000000 \\ \hline
        CLONALG              & 75.00\% & 0.5000000000 \\ \hline
        AIRS                 & 74.00\% & 0.5099019514 \\ \hline
        ID3                  & 71.00\% & 0.5248906592 \\ \hline
    \end{tabular}
\end{table}

As tabelas \ref{tbl:dev_table_aust_correct} e \ref{tbl:dev_table_ger_correct} mostram o percentual de instâncias corretamente classificadas e o erro médio, ordenadas pelo primeiro\footnote{Os valores para o conjunto de dados \emph{cr.ger} podem parecer estranhos, mas isso se deve à maneira como os dados foram divididos. O número total de instâncias é 1000, e foi utilizado \emph{cross-validation} de 10 \emph{folds}, com 100 instâncias cada. Dessa forma, a porcentagem de instâncias corretamente classificadas é sempre um número inteiro.}. Geralmente, um valor maior de instâncias classificadas corretamente implica um erro menor, mas esse nem sempre é o caso. Para classificadores que associam um percentual de certeza à classificação, o erro médio indica \emph{quão} errada a classificação foi, e não apenas se ele foi errada ou não. Essa medida pode ser mais ou menos importante, dependendo do objetivo da classificação.

\begin{table}[h]
    \centering
    \caption{Falsos positivos e falsos negativos (cr.aust)}
    \label{tbl:dev_table_aust_youden}
    \vspace{0.5cm}
    \begin{tabular}{|l|c|c|c|c|c|}
        \hline
        \textbf{Algoritmo} & \textbf{Youden} & \textbf{Falsos positivos} & \textbf{Falsos negativos} \\
        \hline
        \rowcolor[gray]{.9}
        J48                  & 0.9091680815 & 0.0645161290 & 0.0263157895 \\ \hline
        \rowcolor[gray]{.9}
        MultilayerPerceptron & 0.8820512821 & 0.0666666667 & 0.0512820513 \\ \hline
        \rowcolor[gray]{.9}
        BayesNet             & 0.8820512821 & 0.0666666667 & 0.0512820513 \\ \hline
        SMO                  & 0.8717948718 & 0.0000000000 & 0.1282051282 \\ \hline
        AIRS2                & 0.8641025641 & 0.0333333333 & 0.1025641026 \\ \hline
        Immunos99            & 0.8307692308 & 0.0666666667 & 0.1025641026 \\ \hline
        Id3                  & 0.7595048630 & 0.1379310345 & 0.1025641026 \\ \hline
        NaiveBayes           & 0.7410256410 & 0.2333333333 & 0.0256410256 \\ \hline
        Lvq2\_1              & 0.5487179487 & 0.4000000000 & 0.0512820513 \\ \hline
        CLONALG              & 0.5314091681 & 0.2580645161 & 0.2105263158 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{Falsos positivos e falsos negativos (cr.ger)}
    \label{tbl:dev_table_ger_youden}
    \vspace{0.5cm}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Algoritmo} & \textbf{Youden} & \textbf{Falsos positivos} & \textbf{Falsos negativos} \\
        \hline
        \rowcolor[gray]{.9}
        BayesNet             & 0.5809523810 & 0.3333333333 & 0.0857142857 \\ \hline
        \rowcolor[gray]{.9}
        NaiveBayes           & 0.5619047619 & 0.3666666667 & 0.0714285714 \\ \hline
        \rowcolor[gray]{.9}
        SMO                  & 0.5476190476 & 0.3666666667 & 0.0857142857 \\ \hline
        MultilayerPerceptron & 0.5000000000 & 0.4000000000 & 0.1000000000 \\ \hline
        J48                  & 0.4095238095 & 0.5333333333 & 0.0571428571 \\ \hline
        AIRS2                & 0.3238095238 & 0.5333333333 & 0.1428571429 \\ \hline
        Immunos99            & 0.3000000000 & 0.6000000000 & 0.1000000000 \\ \hline
        Lvq2\_1              & 0.2952380952 & 0.6333333333 & 0.0714285714 \\ \hline
        Id3                  & 0.2862745098 & 0.5666666667 & 0.1470588235 \\ \hline
        CLONALG              & 0.1666666667 & 0.8333333333 & 0.0000000000 \\ \hline
    \end{tabular}
\end{table}

As tabelas \ref{tbl:dev_table_aust_youden} e \ref{tbl:dev_table_ger_youden} mostram o índice de Youden e as taxas de falsos positivos e falsos negativos, ordenadas pelo primeiro. O índice de Youden é um cálculo que combina a taxa de falsos positivos e negativos, dando maior relevância onde os dois valores são menores. Nos resultados do WEKA, a sensibilidade é chamada de taxa de verdadeiros positivos. A especificadade não faz parte dos valores, mas pode ser calculada como $1 - taxa\ de\ falsos\ positivos$.

\begin{table}[h!]
    \centering
    \caption{Tempos de treinamento e teste em segundos (cr.aust)}
    \label{tbl:dev_table_aust_times}
    \vspace{0.5cm}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Algoritmo} & \textbf{Tempo de treinamento} & \textbf{Tempo de teste} \\
        \hline
        \rowcolor[gray]{.9}
        NaiveBayes           &   0.002 & 0.001 \\ \hline
        \rowcolor[gray]{.9}
        BayesNet             &   0.029 & 0.000 \\ \hline
        \rowcolor[gray]{.9}
        ID3                  &   0.032 & 0.005 \\ \hline
        J48                  &   2.715 & 0.000 \\ \hline
        Lvq2\_1              &   5.383 & 0.001 \\ \hline
        MultilayerPerceptron &  17.993 & 0.003 \\ \hline
        AIRS                 &  23.238 & 0.012 \\ \hline
        SMO                  &  57.207 & 0.001 \\ \hline
        Immunos              &  69.876 & 0.007 \\ \hline
        CLONALG              & 175.078 & 0.002 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h!]
    \centering
    \caption{Tempos de treinamento e teste em segundos (cr.ger)}
    \label{tbl:dev_table_ger_times}
    \label{tbl:dev_table_last}
    \vspace{0.5cm}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Algoritmo} & \textbf{Tempo de treinamento} & \textbf{Tempo de teste} \\
        \hline
        \rowcolor[gray]{.9}
        NaiveBayes           &   0.004 & 0.001 \\ \hline
        \rowcolor[gray]{.9}
        ID3                  &   0.089 & 0.000 \\ \hline
        \rowcolor[gray]{.9}
        BayesNet             &   0.176 & 0.007 \\ \hline
        Lvq2\_1              &   4.214 & 0.001 \\ \hline
        J48                  &   5.480 & 0.000 \\ \hline
        AIRS                 &  15.037 & 0.034 \\ \hline
        MultilayerPerceptron &  58.003 & 0.012 \\ \hline
        SMO                  & 118.713 & 0.001 \\ \hline
        Immunos              & 199.922 & 0.017 \\ \hline
        CLONALG              & 331.366 & 0.003 \\ \hline
    \end{tabular}
\end{table}

As tabelas \ref{tbl:dev_table_aust_times} e \ref{tbl:dev_table_ger_times} mostram os tempos de treinamento e teste, ordenados pelo primeiro. Em todos os casos, o tempo de treinamento é muito superior ao tempo de teste. Isso é comum na maioria dos algoritmos. É importante notar que o tempo de treinamento é sempre constante, enquanto outros têm um tempo alto de treinamento inicial, mas os treinamentos subsequentes têm um custo muito menor. Esse fator não foi avaliado nesse experimento.

Uma tendência que já pode ser vista nas tabelas e que é comum em todos os dados do experimento é a de que os resultados para o conjunto de dados \emph{cr.aust} são sempre melhores em relação ao \emph{cr.ger}. O desempenho é sempre cerca de 1.5 vezes ``melhor'' no primeiro do que no segundo. Apenas com os resultados desse experimento não é possível indicar com certeza o motivo desse comportamento, mas imagina-se que isso se deve ao fato do conjunto de dados \emph{cr.ger} ser maior (600 contra 1000 instâncias) e possuir mais atributos (14 contra 20).

Isso também ajuda a mostrar a importância da utilização de mais de um conjunto de dados na execução de qualquer experimento. Utilizando apenas um, não é possível saber se o modelo gerado terá o mesmo desempenho em conjuntos de dados diferentes, com características diferentes, como número de instâncias e atributos, tipo de dados, distribuição dos valores, etc.

Com mais de um conjunto de dados é possível comparar o desempenho do algoritmo em diferentes situações, evitando análises incompletas ou tendenciosas. Como pode ser observado nos gráficos, o desempenho de alguns algoritmos foi consideravelmente melhor em um conjunto de dados que no outro. Caso apenas um dos conjuntos de dados tivesse sido usado, isso poderia favorecer alguns algoritmos ou penalizar outros.

\subsection{Resultados por algoritmo}

Nessa seção são apresentados gráficos com os resultados dos testes agrupados pelos algoritmos (figuras \ref{fig:dev_graph_first} à \ref{fig:dev_graph_last}). Após a análise de cada conjunto de dados, essa análise permite comparar os resultados entre os algoritmos. Os valores comparados são os mesmos (porcentagem de instâncias corretamente classificadas, erro quadrático médio, taxa de falsos positivos e falsos negativos e tempos de treinamento e testes). Dessa forma, além da comparação entre os gráficos dessa seção, é possível fazer a comparação com as tabelas da seção anterior.

\begin{figure}[h]
    \centering
    \caption{Porcentagem correta}
    \label{fig:dev_graph_correct}
    \label{fig:dev_graph_first}
    \includegraphics[width=1\textwidth]{img/graph_perc_correct.jpg}
\end{figure}

O gráfico \ref{fig:dev_graph_correct} mostra a porcentagem de instâncias corretamente classificadas. Esse é o primeiro valor a ser considerado nas análises de desempenho, por ser uma medida simples. Com relação a esse atributo, a maioria dos classificadores teve resultado semelhante. A diferença entre o melhor e o pior dos classificadores foi de 19\% e 14\% por cento para o \emph{cr.aust} e \emph{cr.ger}, respectivamente. Ainda, se forem desconsiderados os dois piores resultados, a diferença cai para 9\% em ambos. Em destaque na porcentagem de instâncias corretamente classificadas ficaram os algoritmos BayesNet, MultilayerPerceptron e SMO. Os algoritmos imunológicos tiveram desempenho mediano no \emph{cr.aust} e menor que a média no \emph{cr.ger}.

\begin{figure}[h]
    \centering
    \caption{Erro quadrático médio}
    \label{fig:dev_graph_error}
    \includegraphics[width=1\textwidth]{img/graph_error.jpg}
\end{figure}

O gráfico \ref{fig:dev_graph_error} mostra o erro quadrático médio. Não houveram diferenças significativas entre os resultados do gráfico anterior e desse. Um classificador que classificou mais instâncias corretamente teve um erro médio menor. Destaca-se nesse gráfico a diferença maior do erro médio entre os dois conjuntos de dados, que foi maior que a diferença entre o número de instâncias classificadas corretamente. É importante lembrar que o erro médio é uma medida útil para comparação entre os valores de uma mesma variável, mas não pode ser usado para comparação entre variáveis (como entre os resultados dos conjuntos de dados), porque a sua escala varia conforme a escala dos valores da variável.

\begin{figure}[h]
    \centering
    \caption{Índice de Youden}
    \label{fig:dev_graph_youden}
    \includegraphics[width=1\textwidth]{img/graph_youden.jpg}
\end{figure}

\begin{figure}[h]
    \centering
    \caption{Taxa de falsos positivos}
    \label{fig:dev_graph_false_pos}
    \includegraphics[width=1\textwidth]{img/graph_false_pos.jpg}
\end{figure}

\begin{figure}[h]
    \centering
    \caption{Taxa de falsos negativos}
    \label{fig:dev_graph_false_neg}
    \includegraphics[width=1\textwidth]{img/graph_false_neg.jpg}
\end{figure}

Os gráficos do índice de Youden, falsos positivos e falsos negativos (\ref{fig:dev_graph_youden}, \ref{fig:dev_graph_false_pos} e \ref{fig:dev_graph_false_neg}) são os mais significativos para essa análise. Como foi comentado no capítulo \ref{chap:eval}, apenas a porcentagem de instâncias classificadas corretamente não é uma medida de suficiente para a avaliação do desempenho de um algoritmo.

Para que a análise seja completa, é necessário analisar o que os falsos positivos e falsos negativos significam no contexto da detecção de fraude. Um falso positivo indica que a instância foi classificada como uma fraude quando na verdade ela não era. Por outro lado, um falso negativo indica que a instância foi classificada como normal quando na verdade era uma fraude\footnote{A terminologia pode ser confusa nesse contexto. Em um sistema de detecção de fraude, "positivo" significa "positivo para fraude", e não que a instância é "boa"}. No contexto da detecção de fraude, um falso negativo é muito mais crítico que um falso positivo, ou seja, quanto mais fraudes forem identificadas, melhor. O número de instâncias normais identificadas como fraude têm bem menos importância nesse contexto.

Desse ponto de vista, um algoritmo como o CLONALG, que classificou corretamente apenas 75\% das instâncias no conjunto de dados \emph{cr.ger} mas que teve taxa de falsos positivos 0 (ou seja, todas as fraudes foram identificadas) pode ser mais interessante do que as redes bayesianas, que classificaram 9\% instâncias corretamente a mais, mas tiveram taxa de falsos negativos entre 5\% e 10\%. Dependendo da aplicação, mesmo uma taxa de falsos negativos de 10\% pode ser inaceitável.

Uma observação interessante é que a taxa de falsos positivos é muito maior no \emph{cr.ger} e que os algoritmos imunológicos tendem a ter um taxa maior que os outros algoritmos, mas uma taxa de falsos negativos similar.

\begin{table}
    \parbox{.45\linewidth}{
        \centering
        \caption{BayesNet}
        \begin{tabular}{c|c c|c c}
            \multicolumn{1}{c}{}  & \multicolumn{2}{c}{cr.aust} & \multicolumn{2}{c}{cr.ger} \\
            \multirow{1}{2.5mm}{} & P & N & P & N \\
            \hline
            P & 37 & 2 & 64 & 10 \\
            N & 28 & 2 & 20 &  6 \\
        \end{tabular}
    }
    \hfill
    \parbox{.45\linewidth}{
        \centering
        \caption{NaiveBayes}
        \begin{tabular}{c|c c|c c}
            \multicolumn{1}{c}{}  & \multicolumn{2}{c}{cr.aust} & \multicolumn{2}{c}{cr.ger} \\
            \multirow{1}{2.5mm}{} & P & N & P & N \\
            \hline
            P & 38 & 7 & 65 & 11 \\
            N & 23 & 1 & 19 &  5 \\
        \end{tabular}
    }
\end{table}

\begin{table}
    \parbox{.45\linewidth}{
        \centering
        \caption{MultilayerPerceptron}
        \begin{tabular}{c|c c|c c}
            \multicolumn{1}{c}{}  & \multicolumn{2}{c}{cr.aust} & \multicolumn{2}{c}{cr.ger} \\
            \multirow{1}{2.5mm}{} & P & N & P & N \\
            \hline
            P & 37 & 2 & 63 & 12 \\
            N & 28 & 2 & 18 &  7 \\
        \end{tabular}
    }
    \hfill
    \parbox{.45\linewidth}{
        \centering
        \caption{SMO}
        \begin{tabular}{c|c c|c c}
            \multicolumn{1}{c}{}  & \multicolumn{2}{c}{cr.aust} & \multicolumn{2}{c}{cr.ger} \\
            \multirow{1}{2.5mm}{} & P & N & P & N \\
            \hline
            P & 34 & 0 & 64 & 11 \\
            N & 30 & 5 & 19 &  6 \\
        \end{tabular}
    }
\end{table}

\begin{table}
    \parbox{.45\linewidth}{
        \centering
        \caption{AIRS}
        \begin{tabular}{c|c c|c c}
            \multicolumn{1}{c}{}  & \multicolumn{2}{c}{cr.aust} & \multicolumn{2}{c}{cr.ger} \\
            \multirow{1}{2.5mm}{} & P & N & P & N \\
            \hline
            P & 35 & 1 & 60 & 16 \\
            N & 29 & 4 & 14 & 10 \\
        \end{tabular}
    }
    \hfill
    \parbox{.45\linewidth}{
        \centering
        \caption{CLONALG}
        \begin{tabular}{c|c c|c c}
            \multicolumn{1}{c}{}  & \multicolumn{2}{c}{cr.aust} & \multicolumn{2}{c}{cr.ger} \\
            \multirow{1}{2.5mm}{} & P & N & P & N \\
            \hline
            P & 30 & 8 & 70 & 25 \\
            N & 23 & 8 &  5 &  0 \\
        \end{tabular}
    }
\end{table}

\begin{table}
    \parbox{.45\linewidth}{
        \centering
        \caption{Immunos}
        \begin{tabular}{c|c c|c c}
            \multicolumn{1}{c}{}  & \multicolumn{2}{c}{cr.aust} & \multicolumn{2}{c}{cr.ger} \\
            \multirow{1}{2.5mm}{} & P & N & P & N \\
            \hline
            P & 35 & 2& 63 & 18 \\
            N & 28 & 412 &  7 \\
        \end{tabular}
    }
    \hfill
    \parbox{.45\linewidth}{
        \centering
        \caption{Lvq2\_1}
        \begin{tabular}{c|c c|c c}
            \multicolumn{1}{c}{}  & \multicolumn{2}{c}{cr.aust} & \multicolumn{2}{c}{cr.ger} \\
            \multirow{1}{2.5mm}{} & P & N & P & N \\
            \hline
            P & 37 & 12 & 65 & 19 \\
            N & 18 &  2 & 11 &  5 \\
        \end{tabular}
    }
\end{table}

\begin{table}
    \parbox{.45\linewidth}{
        \centering
        \caption{ID3}
        \begin{tabular}{c|c c|c c}
            \multicolumn{1}{c}{}  & \multicolumn{2}{c}{cr.aust} & \multicolumn{2}{c}{cr.ger} \\
            \multirow{1}{2.5mm}{} & P & N & P & N \\
            \hline
            P & 35 & 4 & 58 & 17 \\
            N & 25 & 4 & 13 & 10 \\
        \end{tabular}
    }
    \hfill
    \parbox{.45\linewidth}{
        \centering
        \caption{J48}
        \begin{tabular}{c|c c|c c}
            \multicolumn{1}{c}{}  & \multicolumn{2}{c}{cr.aust} & \multicolumn{2}{c}{cr.ger} \\
            \multirow{1}{2.5mm}{} & P & N & P & N \\
            \hline
            P & 37 & 2 & 66 & 16 \\
            N & 29 & 1 & 14 &  4 \\
        \end{tabular}
    }
\end{table}

\begin{figure}[h]
    \centering
    \caption{Tempo de treinamento em segundos}
    \label{fig:dev_graph_train_time}
    \includegraphics[width=1\textwidth]{img/graph_train_time.jpg}
\end{figure}

\begin{figure}[h]
    \centering
    \caption{Tempo de teste em segundos}
    \label{fig:dev_graph_test_time}
    \label{fig:dev_graph_last}
    \includegraphics[width=1\textwidth]{img/graph_test_time.jpg}
\end{figure}

No gráfico de tempo de treinamento (\ref{fig:dev_graph_train_time}), pode-se ver que existe uma diferença muito grande entre os algoritmos (note a escala logarítmica). Em um extremo, as redes bayesianas e o algoritmo ID3 têm tempo de treinamento ínfimo, inferior a um segundo. Em outro, os algoritmos imunológicos levaram de 15 a 330 segundos. Embora esses números não sejam considerados altos em relação a esse tipo de atividade computacional, são várias ordens de magnitude maiores que os algoritmos mais rápidos. Apesar disso, o tempo de execução geralmente não é considerado um fator decisivo na comparação dos algoritmos se mantiver-se em uma faixa aceitável para a execução.

É interessante notar que o tempo de treinamento dos algoritmos para o \emph{cr.aust} é aproximadamente a metade em relação ao \emph{cr.ger}. Levando em consideração que o número de instâncias também é aproximadamente a metade, pode-se ver que o número de instâncias não é uma fator significativo no tempo de treinamento. O mesmo pode ser observado para o tempo de teste (\ref{fig:dev_graph_test_time}), mas esses valores são tão baixos, tanto isolados quanto em relação ao tempo de treinamento, que são praticamente irrelevantes.

Novamente, a análise dos tempos de treinamento e testes dos algoritmos imunológicos deve levar em consideração que o critério de parada desses algoritmos não é um número de iterações fixo. O processo de treinamento só é finalizado quando um limiar pré-definido de similaridade é atingido. Esse limiar é um parâmetro para a execução do algoritmo e pode ser configurado (assim como outros parâmetros) caso o tempo de execução seja considerado um fator mais importante que os outros.
