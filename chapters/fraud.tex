\chapter{Detecção de fraude}

A fraude pode ter origem tanto interna quanto externa a uma organização. Por exempo, uma empresa está sujeita a fraude por seus administradores (denominada de alto-nível) ou empregados que não sejam gestores (baixo-nível) \cite{Phua2010}. Em um documento de 2012, a Associação de Investigadores Certificados de Fraude (Association of Certified Fraud Examiners, ACFE) definiu a fraude interna como a exploração ilegal dos recursos e bens de uma empresa, por um empregado, para enriquecimento próprio \cite{ACFE2012}.

Já na fraude externa, os seus autores dividem-se em três perfis: casual, criminal e crime organizado \cite{Phua2010}. Criminosos casuais apresentam comportamento aleatório, transgredindo as leis quando têm oportunidade, tentação ou em períodos de dificuldades financeiras. Por outro lado, indivíduos ou grupos organizados são mais perigosos porque tentam esconder ou dissimular sua verdadeira identidade, além de evoluir seu \emph{modus operandi} com o tempo, tentando burlar os sistemas de detecção e evitar a sua identificação. Assim, é importante levar-se em consideração essa constante interação entre os sistemas de detecção e os fraudadores profissionais. Essas categorias de fraudadores geralmente atuam em um setor específico: as fraudes internas e de seguro são mais frequentemente exploradas por criminosos comuns, enquanto fraudes de cartão de crédito e telecomunicações são vítimas de fraudadores profissionais.

O monitoramento de sistemas com o objetivo de encontrar comportamentos fraudulentos já existia muito antes da utilização dos sistemas computacionais tornarem-se ferramentas comuns. Antes havia um processo denominado auditoria: gerar, armazenar e revisar um registro cronológico de eventos de um sistema \cite{Bace2000}. Os principais objetivos dos sistemas de auditoria são identificar os usuários do sistema, impedir o uso impróprio, e auxiliar na reconstrução de eventos e na estimativa, quantificação e qualificação de danos.

O primeiro trabalho a considerar necessária a auditoria automática de sistemas foi \citet{Anderson1972}. Nesse trabalho, Anderson classifica os riscos e ameaças a sistemas, diferenciando fontes internas e externas, como na figura \ref{fraud:and}. Ele também cita diversos objetivos para um sistema de auditoria:

\begin{enumerate}[a)]
    \item Prover informações suficientes para que o problema possa ser localizado, mas que não exponham detalhes que possibilitem um ataque.
    \item Obter dados de diversas fontes para otimizar o conteúdo do banco de dados.
    \item Discernir uma atividade ``normal'' do sistema, para que se possa detectar abusos interno.
    \item Levar em consideração as estratégias dos invasores no projeto do sistema.
\end{enumerate}

A detecção de fraude é apenas uma das etapas de um sistema chamado de \emph{controle de fraude}. Nesse contexto, a detecção automática ajuda a reduzir o trabalho manual de verificação das instâncias \cite{Phua2010}. O objetivo principal desses sistemas é identificar padrões de transações suspeitas em meio às transações comuns de uma organização. O fraudador pode, por exemplo, contratar um seguro usando informações de outra pessoa ou informações falsas. O sistema procura detectar e impedir a fraude o mais cedo possível.

\renewcommand{\arraystretch}{1.5}
\begin{table}[h!]
    \caption{Matriz de ameaças}
    \label{fraud:and}
    \centering
    \begin{tabular}{c p{4cm}|>{\centering\arraybackslash}p{4cm}|>{\centering\arraybackslash}p{4cm}|}
        \cline{3-4}
        & & Uso não autorizado dos dados/programa & Uso autorizado dos dados/programa \\
        \hhline{~---}
        \multicolumn{0}{c|}{} & Uso não autorizado do computador & Invasão externa & \cellcolor{gray!90} \\
        \cline{2-4}
        \multicolumn{0}{c|}{} & Uso autorizado do computador & Invasão interna & Abuso de poder \\
        \cline{2-4}
    \end{tabular}
    \\ Fonte: \cite{Anderson1972}.
\end{table}

Geralmente não é possível ter absoluta certeza sobre a legitimidade das transações de um negócio a partir dos dados disponíveis. Não seria possível verificar todas as entidades com as quais uma empresa mantém relações, que em algumas empresas podem ser milhares. Assim, não existe uma técnica infalível para a detecção de fraudes. Isso não significa que elas não possam ser detectadas. A melhor alterantiva, na prática, é uma busca por possíveis evidências de fraude nos dados disponíveis. Métodos matemáticos e estatísticos são utilizados para comparar um banco de dados de transações existentes com as novas, com o objetivo de encontrar evidências de possíveis fraudes. Mesmo assim, geralmente há um processo de análise e revisão caso a caso por um especialista.

Ainda, segundo a pesquisa apresentada no mesmo trabalho, o motor analítico desse tipo de sistema pode ser composto de um ou mais métodos, tais como: Sistemas Imunológicos Artificiais, inteligência artificial, auditoria, bancos de dados, computação distribuída e paralela, econometria, sistemas especialistas, lógica nebulosa, algoritmos genéticos, aprendizagem de máquina, redes neurais, reconhecimento de padrões, estatística, visualização, entre outros.

Dois conceitos relacionados à detecção em geral são falsos positivos e falsos negativos. Falsos positivos são instâncias erroneamente classificadas, por exemplo, uma transação comum que é classificada como fraudulenta. Falsos negativos são o oposto: uma transação fraudulenta que é classificada como comum. O número de falsos positivos aumenta o trabalho desnecessário na fase de revisão, enquanto os falsos negativos reduzem a eficácia da detecção.

A redução dos falsos positivos é um dos objetivos principais de um sistema de detecção. Os falsos negativos, no entanto, são quase impossíveis de serem eliminados completamente, em qualquer sistema de detecção \cite{Michie1994}. Mesmo um sistema capaz de reconhecer sinais de fraudes existentes não é suficiente para um ambiente real. Fraudadores tentam constantemente superar os sistemas de detecção, evoluindo o seu \emph{modus operandi} com o tempo, novos métodos são criados, novos fraudadores entram em atividade. Um sistema que almeje deter o maior número possível deve ser constantemente atualizado para se adaptar às mudanças de um ambiente tão dinâmico.

Dependendo do domínio da organização, para que um sistema possa prever fraudes com antecedência suficiente para que elas sejam evitadas, ele deve monitorar constantemente as novas transações em andamento. Esse fator reduz a utilização de sistemas que necessitam de um longo tempo de treinamento ou de análise. O ideal seria que ele estivesse em constante execução, analisando as transações conforme elas ocorrem. Para aplicações grandes ou descentralizadas, pode ser muito difícil conseguir isso sem afetar a performance geral das transações.

Para cada domínio, tipos diferentes de fraude podem existir, e mais de um tipo pode ocorrer simultaneamente, sem uma ordem definida.

\section{Dados}
\label{fraud:data}

Existem alguns conceitos sobre as bases de dados que são característicos da área de mineração de dados e aprendizagem de máquina. O número de instâncias na base é chamado de número de \emph{amostras} e o número de atributos de cada instância é chamado de número de \emph{características} (em inglês, \emph{samples} e \emph{features}).

Os atributos das instâncias em um banco de dados usado para detecção de fraude geralmente limitam-se a valores binários, numéricos, categóricos ou uma mistura desses três. Os atributos específicos usados geralmente são semelhantes. Aplicações de seguro utilizam o histórico do cliente: tempo de contrato, histórico e total de pagamentos, lucro anual valor médio depositado em conta bancária. Para fraudes de crédito, utilizam-se informações sobre as transações: valor, data, localização geográfica, conta de destino, tempo de conta, etc. Fraudes em seguros de automóveis utilizam valores binários para atributos como acidente e tratamento hospitalar, além de dados do motorista, custo, tipo de ferimento, etc.

O número de instâncias positivas nas bases de dados de fraude é geralmente muito reduzido: as fraudes representam um percentual muito pequeno em relação ao número de transações legítimas de uma organização, geralmente menor do que 20\%. Métodos de detecção de fraude nunca são perfeitos: deve existir um mecanismo para lidar com as fraudes que não são identificadas a tempo de serem impedidas.

A obtenção de bancos de dados reais para teste é difícil, já que empresas e organizações, por razões legais e competitivas não disponibilizam informações desse tipo. Assim, é difícil encontrar bases de dados públicos para que os testes sejam realizados. Outra desvantagem comumente encontrada nesses bancos de dados é o fato dos dados estarem alterados, para a preservação da confidencialidade dos clientes das empresas fornecedoras. Apesar dos dados ainda poderem ser utilizados normalmente em ambientes de teste, nao é possível, como seria caso se tivesse acesso aos dados originais, derivar regras de classificiação dos resultados dos testes. Por exemplo, observando os resultados, seria possível perceber que um valor alto em um atributo leva a instância ser classificada como fraudulenta na maioria dos casos. Em uma base de dados esse atributo teria uma descrição informativa, mas isso é perdido em uma base alterada, onde ele seria descrito por um identificador sem significado, como ``atributo 5''.

Uma alternativa é a criação de um banco de dados artificial, inspirado em dados reais. A eficácia dessa técnica é limitada pela capacidade do criador do banco em prever o maior número de casos possíveis, o que geralmente é muito inferior à variedade das situações reais. Mesmo assim, essa técnica é comumente empregada na fase de concepção e teste, devido à dificuldade de obtenção de dados.

\section{Implementação}

A maioria dos sistemas de detecção de fraude opera usando listas negras (\emph{black-lists}) de dados (transações, contas, etc.), que são comparadas com as nova instâncias. Algumas utilizam regras fixas para a classificação. A figura \ref{fig:fraud_data} mostra a organização dos dados nesses sistemas. Uma parte do banco de dados é usada para o treinamento. Esses são os dados onde o sistema aprenderá os padrões e regras utilizados para a detecção. O restante das instâncias é usada para a avaliação do treinamento. Também é comum que haja bancos de dados distintos para o treinamento e avaliação.

\begin{figure}[h!]
    \centering
    \caption{Dados para a análise}
    \label{fig:fraud_data}
    \includegraphics[width=0.75\textwidth]{img/fraud-data.png}
    \\ Fonte: \cite{Phua2010}.
\end{figure}

A maioria dos estudos relacionados à detecção de fraude considera a detecção de \emph{outliers} como uma ferramenta principal de detecção \cite{Aral2011}. Existem muitos métodos aplicados à detecção de fraude: auditoria, sistemas especialistas, lógica nebulosa (\emph{fuzzy}), redes neurais, reconhecimento de padrões, árvores de decisão, regressão, etc \cite{Huang2010}. Considerando os dados dividos conforme a figura \ref{fig:fraud_data}, as duas técnicas mais usadas são:

\begin{enumerate}[a)]
\item Dados para treinamento classificados (A + B + C + D) processados por um algoritmo supervisionado.
\item Instâncias legais (C) processadas por um algoritmo semi-supervisionado.
\end{enumerate}

Algoritmos supervisionados examinam as instâncias previamente classificadas (A + B + C + D) para identificar matematicamente os padrões presentes nas classificadas como fraudulentas. Os algoritmos mais utilizados nessa categoria são as redes neurais. Outros algoritmos incluem máquinas de vetores de suporte (\emph{support vector machine}, SVM), árvores de decisão e raciocínio baseado em casos. Para aumentar a eficácia dos métodos supervisionados, esses algoritmos podem ser aplicados em sequência. Também podem ser combinados resultados de bancos de dados distintos.

Algoritmos não-supervisionados atuam sobre dados não classificados (A + C + E + F), e o seu objetivo é agrupar os dados em padrões, para que estes sejam mais facilmente analisados, combinando a detecção humana e a computação da máquina. Exemplos desses algoritmos são redes neurais não supervisionadas, análise de ligações (\emph{link analysis}) e mineração de grafos (\emph{graph mining}).

A combinação de dois ou mais algoritmos supervisionados, ou de algoritmos supervisionados e não-supervisionados, chamados de algoritmos híbridos, é uma grande área de pesquisa. Também são utilizados algoritmos supervisionados em bancos de dados que contêm apenas instâncias legais (C). Regras são geradas e testadas na base de dados, e aquelas que identificam padrões nesses dados são descartadas. Esses algoritmos são chamados de semi-supervisionados, porque apesar de não fazerem distinção entre dados legais e ilegais, os dados ainda necessitam ser classificados para que sejam utilizados no seu treinamento.

Autores como Phua fazem muitas críticas ao uso de dados previamente classificados para o treinamento dos sistemas \cite{Phua2010}. A classificação atrasa o processo de detecção, aumenta o tempo de reação a novos tipos de fraudes e pode ser cara e difícil de se obter. Pode ainda ser incorreta, tendenciosa e expor dados sigilosos, dependendo do tipo de aplicação. Assim, instâncias de treinamento e avaliação (A + C + E + F, sem classificações) devem ser combinadas e processadas por um algoritmo não-supervisionado, detectando regras, pontuações ou anomalias visuais nos dados avaliados.

Um sistema que detecte e reporte uma fraude muito tempo depois de ela ter ocorrido permite que o fraudador consiga causar um dano substancial. Em geral, esse tempo de resposta de um sistema a partir do momento em que uma fraude é concretizada até a sua detecção é crucial para a eficácia do sistema em de fato proteger o ambiente em que é inserido.

Os sistemas de detecção podem ser divididos em dois tipos gerais, denominados \emph{on-line} e \emph{off-line}, enquanto alguns incorporam características dos dois modelos e outros têm um processo distinto para ambos, que interagem entre si para gerar o resultado final.

\iffalse

\cite{Huang2010}.

\fi

\section{Critérios de avaliação}
\label{sec:fraud_criteria}

Phua e outros autores listam as diversas medidas de performance utilizadas em trabalhos recentes na área de detecção de fraude \cite{Phua2010}. Os métodos tradicionais de medição, como a taxa de positivos (número de fraudes detectadas corretamente dividido pelo número de fraudes verdadeiras) e a precisão a um determinado limite (número de instâncias classificadas corretamente, dividido pelo número total de instâncias) foram abandonados pelos trabalhos recentes, devido à natureza peculiar da detecção de fraude.

A razão para isso é que o custo das classificações errôneas, no caso da detecção de fraude, são irregulares, incertos, variam de exemplo a exemplo e podem variar conforme o tempo. Falsos negativos são geralmente mais custosos do que falsos positivos. Um falso positivo geralmente leva apenas a uma verificação desnecessária por um especialista. Um falso negativo, no entanto, acarreta em uma fraude que não é detectada pelo sistema e não será reportada, deixando o fraudador impune. Mesmo assim, muitos dos sistemas de detecção comerciais, como a maioria dos departamentos governamentais que atuam na área de detecção de fraude, utilizam valores monetários como medida de avaliação \cite{Phua2010}.

Em relação à comparação da eficácia dos métodos, destacam-se os seguintes critérios:

\begin{enumerate}[a)]
    \item Similaridade de uma instância com os exemplos de fraude conhecidos divida pela dissimilaridade com exemplos legais.
    \item Análise da curva ROC (\emph{Receiver Operating Characteristic}, Característica de Operação do Receptor): a taxa de verdadeiros positivos para falsos positivos.
    \item Análise da área sob a curva ROC, que mede a probabilidade de uma instância positiva ser classificada como "mais positiva" do que uma instância negativa.
    \item Entropia cruzada: mede a diferença entre o valor atribuído na classificação de uma instância e o valor real atribuído àquela instância nos dados de teste.
    \item Escore Brier: o erro quadrático médio, ou seja, a média do somatório dos quadrados da diferença entre a classificação de uma instância e a classificação real.
    \item Alguns trabalhos adotam um critério peculiar: as instâncias são classificadas de acordo com o seu valor monetário. Esse valor pode ser tanto explícito quanto baseado em modelos financeiros.
\end{enumerate}

Em relação à eficiência dos métodos, destacam-se os seguintes critérios:

\begin{enumerate}[a)]
    \item Velocidade de detecção (tempo até o alarme).
    \item Número de tipos ou estilos de fraude detectados.
    \item Processo de de detecção em tempo real ou em lote.
\end{enumerate}

\subsection{\emph{Cross-validation}}

Quando um modelo é criado à partir de um conjunto de dados e os testes são executados sobre esse mesmo conjunto, é muito provável que eles apresentem um bom resultado. No entanto, isso não garante que o modelo pode ser aplicado com a mesma eficácia sobre novos dados, o que geralmente é o objetivo dos sistemas de detecção.

Para que seja possível avaliar se um modelo pode prever novos dados após o treinamento, a base de dados deve ser dividida em duas partes: um conjunto de treinamento e um conjunto de teste. O modelo é criado utilizando apenas os dados de treinamento e avaliado utilizando os dados de teste.

Caso o resultado dos testes de um modelo quando aplicado aos mesmos dados utilizados no treinamento seja bom, mas o resultado quando aplicado aos dados de teste sejam ruims, diz-se que ocorre \emph{overfitting}: o modelo ajusta-se tanto aos dados de treinamento que não consegue criar regras genéricas o suficiente para identificar amostras semelhantes mas não exatamente iguais.

Há ainda a possibilidade do modelo não gerar um resultado bom nem mesmo para os dados de treinamento. Nesse caso, diz-se que ocorre \emph{underfitting}: o modelo não é capaz de criar regras que se ajustem aos dados de treinamento.

No entanto, o resultado dessa separação pode ser altamente dependente da separação dos dados. Separar os dados de forma diferente geralmente altera o resultado dos testes. Para evitar essa dependência, pode ser utilizado um processo denominado \emph{cross-validation}:

\begin{enumerate}[a)]
    \item Dividir aleatoriamente os dados em dois conjuntos, treinamento e testes.
    \item Criar o modelo com base no conjunto de dados de treinamento.
    \item Testar o modelo utilizando o conjunto de dados de testes.
    \item Repetir os passos a) a c).
    \item Calcular a média e o erro padrão da média dos resultados de cada iteração.
\end{enumerate}

\subsection{Avaliação de classificadores}

Classificadores binários são aqueles que, para um dado conjunto de valores de entrada, geram como valor de saída um valor Booleano: verdadeiro ou falso, positivo ou negativo. Os sistemas de detecção de fraude se situam, na maioria dos casos, nessa categoria: os dados referentes a uma instância passam pelo sistema de detecção e são classificados como legítimos ou fraudulentos \cite{Bewick2004}. Sistemas mais complexos podem gerar saídas com mais informações sobre a instância, como o grau de certeza da previsão ou o grau de semelhança entre a instância e os dados da base.

A avaliação dos classificadores binários é feita com base em uma \emph{tabela de confusão}, conforme mostrado na tabela \ref{fraud:confusion}. Nessa tabela são listados o número de valores (ou porcentagem) para cada combinação de saída do sistema e a classificação real. Instâncias corretamente classificadas ocupam as colunas Positivo e Negativo, enquanto instâncias cujo classificação difere da realidade ocupam as colunas ``Falsos positivos'' e ``Falsos negativos''.

\renewcommand{\arraystretch}{1.5}
\begin{table}[h!]
    \vspace{1cm}
    \caption{Tabela de confusão}
    \centering
    \begin{tabular}{c l c c}
        & & \multicolumn{2}{c}{\textbf{Dados reais}} \\
        \multirow{3}{5mm}{\begin{sideways}\parbox{20mm}{\textbf{Saída}}\end{sideways}} & \multicolumn{1}{c|}{} & Positivo & Negativo \\
        \cline{2-4}
        & \multicolumn{1}{c|}{Positivo} & Positivo & Falso positivo\\
        & \multicolumn{1}{c|}{Negativo} & Falso negativo & Negativo\\
    \end{tabular}
    \label{fraud:confusion}
    \vspace{1cm}
\end{table}

Como exemplo, inspirado em \citet{Bewick2004}, é apresentado nessa seção um sistema de detecção de fraude, que considera como único atributo das instâncias o número de ocorrências de um determinado valor. Nesse ambiente simplificado, a instância é considerada fraudulenta caso um limiar de ocorrências seja ultrapassado.

Esse sistema de testes utiliza como único critério de avaliação o número de ocorrências (segunda coluna). Um \emph{limiar de classificação} é definido: um parâmetro que o sistema de detecção utilizará para guiar a previsão da detecção. Se o limiar de classificação fosse 1, todas as instâncias que tivessem mais de uma ocorrência (nos valores de exemplo, as instâncias 0 e 2) seriam consideradas fraudulentas.

Um exemplo do resultado de um teste nesse sistema é mostrado na tabela \ref{fraud:ex}. As colunas sob ``Dados reais'' mostram o número de instâncias fraudulentas e legítimas; as linhas sob ``Saída'' mostram a classificação gerada pelo sistema. A partir desses dados, a avaliação dos resultados é feita usando dois conceitos: sensibilidade e especificidade.

\renewcommand{\arraystretch}{1.5}
\begin{table}[h!]
    \centering
    \caption{Exemplo de tabela de confusão}
    \label{fraud:ex}
    \begin{tabular}{c l c c c}
        & & \multicolumn{2}{c}{\textbf{Dados reais}} \\
        \multirow{3}{5mm}{\begin{sideways}\parbox{20mm}{\textbf{Saída}}\end{sideways}} & \multicolumn{1}{c|}{} & Fraude & Legítimo & \multicolumn{1}{|c}{Total} \\
        \cline{2-5}
        & \multicolumn{1}{c|}{Fraude}   & 300 & 200   & \multicolumn{1}{|c}{500}  \\
        & \multicolumn{1}{c|}{Legítimo} & 100 & 1000  & \multicolumn{1}{|c}{1100} \\
        \cline{2-5}
        & \multicolumn{1}{c|}{Total}    & 400 & 1200  & \multicolumn{1}{|c}{1600} \\
    \end{tabular}
\end{table}

\subsection{Sensibilidade e especificidade}

\emph{Sensibilidade} refere-se à proporção de instâncias corretamente classificadas como positivas. \emph{Especificidade} refere-se à proporção de instâncias corretamente classificadas como negativas. Tomando como exemplo os dados da tabela \ref{fraud:ex}, a sensibilidade é igual a 300 / 400 = 0.75; e a especificidade é igual a 1000 / 1200 = 0.8333. Ou, visto de outra maneira, 75\% das fraudes foram realmente classificadas como fraudes; e 83.33\% das instâncias legítimas foram classificadas como legítimas.

Apenas a consideração desses dois valores pode levar a uma correta avaliação dos resultados do teste, principalmente nos domínios da detecção de fraude. Uma alta sensibilidade não necessariamente implica em uma alta especificidade, e vice versa. Dessas duas informações são derivados os \emph{valores preditivos positivos e negativos}.

\subsection{Valores preditivos}

O \emph{valor preditivo positivo} é a chance de uma instância ser realmente uma fraude caso seja classificada como tal pelo sistema. O \emph{valor preditivo negativo} é a chance de uma instância ser realmente legítima caso seja classificada como tal pelo sistema. Para os dados de exemplo, o valor preditivo positivo é 300 / 500 = 0.6; e o valor preditivo negativo é 1000 / 1100 = 0.9091. Ou, visto de outra maneira, 60\% das instâncias que foram classificadas como fraude eram realmente fraudes, e 90.91\% das instâncias classificadas como legítimas eram realmente legítimas.

Esses dois valores são o oposto da sensibilidade e especificidade, respectivamente. Enquanto os valores preditivos dão uma avaliação direta sobre os resultados dos testes, a sensibilidade e especificidade não são afetadas pela proporção dos valores nas instâncias, ou seja, não são alteradas quando há uma alteração na proporção de fraudes.

\subsection{Taxas de verossimilhança}

A sensibilidade e especificidade tornam-se ainda mais úteis quando combinadas, gerando as taxas de verossimilhança. A taxa de verossimilhança de um resultado positivo (LR\textsuperscript{+}) é a razão entre a probabilidade de um resultado positivo no teste caso a instância seja realmente positiva (coluna "positivo" da tabela de confusão) e a probabilidade de um resultado positivo no teste caso a instância seja na verdade negativa:

\begin{equation}
    \vspace{2mm}
    LR^{+}=\frac{sensibilidade}{1 - especificidade}
    \vspace{2mm}
\end{equation}

No exemplo, LR\textsuperscript{+} = 0.75 / (1 - 0.8333) = 4.4991. Isso significa que um resultado positivo nos testes é 4.4991 vezes mais provável para instâncias que são realmente positivas do que para aquelas que não são.

De maneira, similar, a taxa de verossimilhança negativa (LR\textsuperscript{-}) é a razão entre a probabilidade de um resultado negativo no teste caso a instância seja realmente negativa (coluna "negativo" da tabela de confusão) e a probabilidade de um resultado negativo no teste caso a instância seja na verdade positiva:

\begin{equation}
    \vspace{2mm}
    LR^{-}=\frac{1 - sensibilidade}{especificidade}
    \vspace{2mm}
\end{equation}

No exemplo, LR\textsuperscript{-} = (1 - 0.75) / 0.8333 = 0.3, o que significa que um resultado negativo no teste é 0.3 vezes mais provável para instâncias que são realmente negativas do que para aquelas que não são.

Desses valores, pode-se atestar a utilidade do método para classificação. Uma alta taxa de verossimilhança positiva indica que o teste é útil para verificar se uma instância é positiva, enquanto uma alta taxa de verossimilhança negativa é útil para verificar se uma instância é negativa. Assim como os valores preditivos, essas taxas são sensíveis à predisposição dos dados na base de dados.

\subsection{Índice de Youden e ROC}

Os dados de teste do exemplo mostrados nas tabelas até agora consideraram apenas um valor como limiar de classificação. Mudanças nesse limiar afetam a precisão dos testes: caso o limiar seja seja igual a -1, todas as instâncias são classificadas como fraudulentas, já que todas possuem como número de ocorrências um número maior ou igual a zero. Por outro lado, caso o limiar seja um número maior do que qualquer uma das instâncias, todas serão classificadas como legítimas. Em sistemas reais, é comum que sejam testados diversos valores para esse limiar sobre uma mesma base de dados, para que o melhor seja identificado e usado no sistema final. A tabela \ref{fraud:youden} é um exemplo de resultados para esse tipo de teste.

\begin{table}[h!]
    \caption{Exemplo de resultados para testes comparativos de limiares}
    \label{fraud:youden}
    \centering
    \begin{tabular}{l c c c c c}
        \hline
        Limiar & Fraudes & Legítimos & Sensibilidade & Especificidade & Índice de Youden \\
        \hline
        0     & 400 &    0 & 1      & 0      & 0      \\
        1     & 395 &  400 & 0.9875 & 0.3333 & 0.3208  \\
        2     & 380 &  600 & 0.95   & 0.5    & 0.45   \\
        3     & 375 &  900 & 0.9375 & 0.75   & 0.6875 \\
        4     & 200 & 1000 & 0.5    & 0.8333 & 0.3333 \\
        99    &   0 & 1200 & 0      & 1      & 0      \\
        \hline
        Total & 400 & 1200 &    -   &    -   &    -   \\
        \hline
    \end{tabular}
    \\ Fonte: inspirado em \citet{Bewick2004}.
\end{table}

Uma medida para a avaliação dos diferentes limiares pode ser a sensibilidade e especificidade. O índice de Youden (J), que é uma derivação desses valores, é uma medida apropriada nesses casos (eq. \ref{fraud:yindex}). Esse índice é um valor normalizado na faixa [0, 1], onde 1 significa um teste perfeito, classificando todas as instâncias corretamente; e 0 significa um teste sem valor nenhum. A tabela \ref{fraud:yindex} mostra os valores para os resultados com diversos limiares. É importante notar como valores extremos maximizam a sensibilidade e a especificidade, mas apenas aqueles limiares que maximizam os dois valores recebem índices significativos.

\begin{equation}
    \vspace{2mm}
    J = sensibilidade + especificidade - 1
    \label{fraud:yindex}
    \vspace{2mm}
\end{equation}

Uma característica importante do índice de Youden é que ele estabelece uma equivalência na relevância dos falsos positivos e negativos. Quando um é mais relevante que o outro, devido à peculiaridades nos dados ou no domínio do problema, ele não é apropriado. Nesses casos, pode-se atribuir pesos diferentes a ambos os valores. Um exemplo de adaptação do cálculo do índice de Youden é mostrado abaixo. Nessa fórmula, os valores ainda são mantidos na mesma faixa, mas falsos positivos recebem o dobro da significância.

\begin{equation}
    \vspace{2mm}
    J = 0.75 * sensibilidade + 0.25 * especificidade
    \vspace{2mm}
\end{equation}

Como pode-se observar na tabela \ref{fraud:yindex}, alterações no valor usado na classificação alteram o número de instâncias classificadas como positivas e negativas. Geralmente os resultados são distribuídos começando com um grande valor de sensibilidade e um valor baixo de especificidade; esses valores convergem até um máximo global; e então terminam em com um valor baixo de sensibilidade e um grande valor de especificidade. A variação desses três valores, e a interação entre eles, é mostrada no gráfico da figura \ref{fraud:threshold}.

\begin{figure}[h!]
    \centering
    \caption{Variação dos valores de avaliação conforme o limiar de detecção}
    \label{fraud:threshold}
    \includegraphics[scale=0.5]{img/threshold.png}
\end{figure}

No lado esquerdo, onde o limiar é muito baixo, a sensibilidade é 1 e a especificidade, zero; enquanto no lado direito, onde o limiar é muito alto, ocorre o oposto: a sensibilidade é zero e a sensibilidade, 1. Conforme o limiar aumenta (começando do lado esquerdo e caminhando para a direita), ocorreu uma diminuição na especificidade (algumas instâncias fraudulentas começam a ser classificadas como legítimas). No entanto, há um aumento muito maior na especificidade (instâncias legítimas começam a ser classificadas corretamente). É possível ver como o índice de Youden mostra a real proporção entre esses dois valores. Uma forma mais sucinta para apresentar esse tipo de informação é através de um gráfico dos valores de sensibilidade e 1 - especificidade, que é denominado ROC (característica operativa do receptor, \emph{receiver operating characteristic}), conforme mostrado na figura \ref{fraud:roc}.

\begin{figure}[h!]
    \centering
    \caption{Gráfico da curva ROC dos valores de exemplo}
    \label{fraud:roc}
    \includegraphics[scale=0.5]{img/roc.png}
\end{figure}

No gráfico é visualmente aparente que o valor 3 como limiar de classificação oferece o melhor balanceamento entre sensibilidade e especificidade. Também é possível perceber como as alterações no limiar influenciam a distribuição desses dois valores. Um teste perfeito, que classificasse todas as instâncias corretamente, teria ambos os valores iguais a 1, tendo portanto um ponto no canto superior esquerdo do gráfico. Os pontos mais próximos dessa localização são aqueles que melhor classificam as instâncias.

Caso as instâncias fossem classificadas aleatoriamente, tendo chances iguais de serem classificadas tanto positivas quanto negativas, a sensibilidade e a especificidade seria ambas 0.5, e o teste não teria qualquer valor. Essa situação é representada pela linha diagonal entre os pontos (0, 1) e (1, 0). Essa linha é outro indicador visual útil: testes abaixo dela (na direção do canto inferior direito) têm muito pouco valor; testes próximos dela têm valor mediano; e testes acima (na direção do canto superior esquerdo) têm grande valor.

Uma das maneiras de quantificar a (dar um valor à) validade de um atributo como variável de diagnóstico é através do cálculo dá área sob a curva ROC (denominada AUROC, \emph{area under the ROC curve}). O teste ideal citado acima teria área igual a 1, enquanto testes completamente aleatórios teriam área 0.5. Testes reais normalmente situam-se entre esses dois valores, com valores mais próximos de 1 representando testes mais precisos.

O cálculo da área pode ser feito somando-se a área dos trapézios formados pela curva. Tomando dois pontos da curva, (0.1667, 0.5) e (0.3125, 0.9375), o trapézio formado por esses pontos e os pontos (0.1667, 0.0) e (0.3125, 0.0) é igual a (0.9375 - 0.5) x (0.3125 + 0.1667)/2 = 0.1048. Aplicando essa regra aos outros pontos da curva, obtêm-se uma área total de 0.8161, ou seja, uma instância fraudulenta tem 81.61\% de ter um número de ocorrências de inadimplência maior do que uma instância legítima.

\subsection{Análise de resultados}

Uma vez que possa ser quantificada, a capacidade de diagnóstico de uma variávei pode ser comparada com outras, simplesmente comparando-se as suas curvas ROC e as áreas sob essas curvas. Variáveis com uma maior área sob a curva geram diagnósticos mais confiáveis. O formato da curva também pode servir como instrumento de análise: uma variável pode ter comportamentos preferíveis caso as condições de teste sejam diferenciadas, ou para filtrar casos específicos. Por exemplo, uma variável que, para valores muito baixos de sensibilidade, apresenta uma alta taxa de especificidade pode ser usada quando quer-se favorecer a especificidade.

A área sob a curva ROC é um método útil para a medição da precisão de diagnósticos, além da comparação de performance entre diferentes testes. No entanto, ela não deve ser tomada como verdade absoluta. A sensibilidde e a especificidade podem manter-se fixas em um ambiente de testes, mas podem variar conforme as características da populaçõ analisada.

Uma consideração importante quando analisa-se o desempenho de dois ou mais sistemas é que muito difícil (ou até mesmo impossível) excluir-se todos os fatores externos, resultando em uma análise completamente imparcial. Nesse caso específico, o resultado dos testes em cada algoritmo é fortemente influenciado pelas características dos dados na base de dados, embora os métodos de análise dos resultados procuram minimizar essa influência.

\iffalse

Uma alternativa é atribuir uma pontuação a cada instância de acordo com uma razão entre a similaridade com casos conhecidos de fraude e a dissimilaridade com casos legais.

\citet{Aral2011} utilizam o número de falsos positivos, falsos negativos e verdadeiros positivos como medida de performance do seu sistema.

\section{Trabalhos relacionados}

Colocar na introdução

O sistema detecção de fraude no comércio eletrônico apresentado em \citet{Huang2010} é um exemplo de sistema que combina dois dois processos de diferentes granularidades que interagem entre si.

\citet{Aral2011} apresentam um sistema de detecção de fraude em prescrições médicas que calcula um fator de risco associado a cada prescrição. Matrizes de incidências são geradas através de uma medida de distância entre valores cruzados (\emph{cross-features}) de uma base de conhecimento. Dessas matrizes são geradas matrizes de riscos, e cada instância da base de dados cujo risco for maior que um limiar é relatada como uma possível fraude. Os autores indicam que o raciocínio por trás desse modelo é de que os padrões no comportamento fraudulento são \emph{outliers} quando considerados no contexto do \emph{dataset} como um todo. Os limiares são configuráveis, permitindo ao usuário um controle sobre o número de falsos positivos gerados.

\fi
